{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1b82d8-020f-41f8-a2b3-0aaece979d63",
      "metadata": {
        "id": "0c1b82d8-020f-41f8-a2b3-0aaece979d63"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.sparse.linalg import eigs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az6Nyct97v38",
        "outputId": "87ff2727-16e9-4419-feb6-57b4febb25c1"
      },
      "id": "Az6Nyct97v38",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d8481f-a13a-4dd9-9a5a-06ca71fa246d",
      "metadata": {
        "id": "82d8481f-a13a-4dd9-9a5a-06ca71fa246d"
      },
      "source": [
        "###### Function for Computing Scaled Laplacian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f71d24b-f868-44a1-b402-e36aeb6cbdef",
      "metadata": {
        "id": "0f71d24b-f868-44a1-b402-e36aeb6cbdef"
      },
      "outputs": [],
      "source": [
        "def scaled_Laplacian(W):\n",
        "    '''\n",
        "    compute \\tilde{L}\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    W: np.ndarray, shape is (N, N), N is the num of vertices\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    scaled_Laplacian: np.ndarray, shape (N, N)\n",
        "\n",
        "    '''\n",
        "    ###Checking if the number of rows and columns of an adjacenecy matrix\n",
        "    ####are same or not\n",
        "    assert W.shape[0] == W.shape[1]\n",
        "\n",
        "    ### First sum each row of the adjacency matrix, and we obtain the degress of each vertex in that row\n",
        "    ### Secondly, a diagonal matrix has been created with degree of each vertex in the diagonal\n",
        "    #### Finally, 'D' is the sparse matrix containing only degrees of each vertex\n",
        "    D = np.diag(np.sum(W, axis=1))\n",
        "\n",
        "    #### 'l' is the unormalized Laplacian Matrix obtained by subtraction\n",
        "    ### of Adjacenecy Matrix from the Diagonal Matrix\n",
        "    L = D - W\n",
        "\n",
        "    #### First of all from the Laplacian Matrix, with the help of 'eigs' function largest value for eigen value and eigne vector\n",
        "    ##### has been evaluated\n",
        "    #### Secondly, eigen value has been only kept\n",
        "    #### Thirdly, eigen value beign a complex number, only real part is kept and saved as lamda_max\n",
        "    lambda_max = eigs(L, k=1, which='LR')[0].real\n",
        "\n",
        "    #### Finally Scaled Laplacian Matrix value is Obtained\n",
        "    return (2 * L) / lambda_max - np.identity(W.shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264a0b1a-5706-4e3e-8e28-191a795bded2",
      "metadata": {
        "id": "264a0b1a-5706-4e3e-8e28-191a795bded2"
      },
      "source": [
        "##### Function for Computing Chebyshev Polynomials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e905db82-5f4e-4983-aaa7-ace27f766491",
      "metadata": {
        "id": "e905db82-5f4e-4983-aaa7-ace27f766491"
      },
      "outputs": [],
      "source": [
        "def cheb_polynomial(L_tilde, K):\n",
        "    '''\n",
        "    compute a list of chebyshev polynomials from T_0 to T_{K-1}\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    L_tilde: scaled Laplacian, np.ndarray, shape (N, N)\n",
        "\n",
        "    K: the maximum order of chebyshev polynomials\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    cheb_polynomials: list(np.ndarray), length: K, from T_0 to T_{K-1}\n",
        "\n",
        "    '''\n",
        "    ### The value of N is set to number of rows of a Laplacian Matric\n",
        "    N = L_tilde.shape[0]\n",
        "\n",
        "    ### cheb_polynimials conatins the zeroth order Chebyshev Polynomial T(0) = np.identity(N)\n",
        "    ### and the first order Chebyshev Polynomial T(1) = L_tilde.copy()\n",
        "    cheb_polynomials = [np.identity(N), L_tilde.copy()]\n",
        "\n",
        "    ### The loop computes the next higher order of Chebyshev Polynomials form order 2 to order k\n",
        "    ### The next order recurrence Chebysehev Polynomial is given by Tk(x) =2xTk-1(x)-Tk-2(x)\n",
        "    for i in range(2, K):\n",
        "        cheb_polynomials.append(2 * L_tilde * cheb_polynomials[i - 1] - cheb_polynomials[i - 2])\n",
        "\n",
        "    return cheb_polynomials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d25aa0e-600f-41cf-b213-459c09cf3cc3",
      "metadata": {
        "id": "5d25aa0e-600f-41cf-b213-459c09cf3cc3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "254eae57-0540-4e5f-af4f-853c85bf5fbd",
      "metadata": {
        "id": "254eae57-0540-4e5f-af4f-853c85bf5fbd"
      },
      "source": [
        "###### Defining the Spatial Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39adb2d0-7a5d-4a2c-946a-099ed30885ff",
      "metadata": {
        "id": "39adb2d0-7a5d-4a2c-946a-099ed30885ff"
      },
      "outputs": [],
      "source": [
        "class Spatial_Attention_layer(nn.Module):\n",
        "    '''\n",
        "    compute spatial attention scores\n",
        "    : in_channels: number of features of a vertex, here for PEMS07, it's 1\n",
        "    : num_of_timesteps represents number of timesegments in the input data\n",
        "    '''\n",
        "    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n",
        "        super(Spatial_Attention_layer, self).__init__()\n",
        "        self.W1 = nn.Parameter(torch.FloatTensor(num_of_timesteps).to(DEVICE))\n",
        "        self.W2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_timesteps).to(DEVICE))\n",
        "        self.W3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n",
        "        self.bs = nn.Parameter(torch.FloatTensor(1, num_of_vertices, num_of_vertices).to(DEVICE))\n",
        "        self.Vs = nn.Parameter(torch.FloatTensor(num_of_vertices, num_of_vertices).to(DEVICE))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (B,N,N)\n",
        "        '''\n",
        "\n",
        "        lhs = torch.matmul(torch.matmul(x, self.W1), self.W2)  # (b,N,F,T)(T)->(b,N,F)(F,T)->(b,N,T)\n",
        "\n",
        "        rhs = torch.matmul(self.W3, x).transpose(-1, -2)  # (F)(b,N,F,T)->(b,N,T)->(b,T,N)\n",
        "\n",
        "        product = torch.matmul(lhs, rhs)  # (b,N,T)(b,T,N) -> (B, N, N)\n",
        "\n",
        "        S = torch.matmul(self.Vs, torch.sigmoid(product + self.bs))  # (N,N)(B, N, N)->(B,N,N)\n",
        "\n",
        "        ##Normalized Spatial Attention scores observes the spatial dependency between the vertices\n",
        "        S_normalized = F.softmax(S, dim=1)\n",
        "\n",
        "        return S_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73bc235e-3f49-4860-8d06-2c5470462e2a",
      "metadata": {
        "id": "73bc235e-3f49-4860-8d06-2c5470462e2a"
      },
      "source": [
        "###### Chebyshev's Convolution with Spatial Attention\n",
        "###### It is alsp known as Graph Convolution with Spatial Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa77ab7-01eb-40c0-801d-26f42aae9c5a",
      "metadata": {
        "id": "5fa77ab7-01eb-40c0-801d-26f42aae9c5a"
      },
      "outputs": [],
      "source": [
        "class cheb_conv_withSAt(nn.Module):\n",
        "    '''\n",
        "    K-order chebyshev graph convolution\n",
        "    '''\n",
        "\n",
        "    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n",
        "        '''\n",
        "        :param K: int\n",
        "        :param in_channles: int, num of channels in the input sequence\n",
        "        :param out_channels: int, num of channels in the output sequence\n",
        "        '''\n",
        "        super(cheb_conv_withSAt, self).__init__()\n",
        "        self.K = K\n",
        "        self.cheb_polynomials = cheb_polynomials\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.DEVICE = cheb_polynomials[0].device\n",
        "\n",
        "        ### Theta consists of a list of learnable weight matrices of each of shape (in_channels x out_channels) for each of the\n",
        "        #### Chebyshev Polynomial, where number of Chebyshev is represneted by 'K'\n",
        "        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n",
        "\n",
        "    def forward(self, x, spatial_attention):\n",
        "        '''\n",
        "        Chebyshev graph convolution operation\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (batch_size, N, F_out, T)\n",
        "        '''\n",
        "        #### Getting shape of the input Graph signal\n",
        "        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for time_step in range(num_of_timesteps):\n",
        "            ####getting the data for a certain time segment\n",
        "            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n",
        "\n",
        "            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n",
        "            #### Looping Over Chebyshev Polynomial Order\n",
        "            #### In order to Perform Graph Convolution Operation with Spatial Attention\n",
        "            for k in range(self.K):\n",
        "\n",
        "                T_k = self.cheb_polynomials[k]  # (N,N)\n",
        "\n",
        "                ###Hadamarad Product between Chebyshev and Spatial Attention\n",
        "                T_k_with_at = T_k.mul(spatial_attention)   # (N,N)*(N,N) = (N,N)\n",
        "\n",
        "                theta_k = self.Theta[k]  # (in_channel, out_channel)\n",
        "\n",
        "                rhs = T_k_with_at.permute(0, 2, 1).matmul(graph_signal)  # (N, N)(b, N, F_in) = (b, N, F_in)\n",
        "\n",
        "                output = output + rhs.matmul(theta_k)  # (b, N, F_in)(F_in, F_out) = (b, N, F_out)\n",
        "            ### Additional dimension is added in order to understand that Graph Concolution\n",
        "            #### for a particular timestamp/timesegment has been done\n",
        "            outputs.append(output.unsqueeze(-1))  # (b, N, F_out, 1)\n",
        "        ####Concatenating the results accross all timesteps and applying Rely activation function\n",
        "        #### on each one of them\n",
        "        return F.relu(torch.cat(outputs, dim=-1))  # (b, N, F_out, T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "211845b8-ae39-4310-b03b-a136227f3f15",
      "metadata": {
        "id": "211845b8-ae39-4310-b03b-a136227f3f15"
      },
      "source": [
        "###### Temporal Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ff2dc14-1684-4673-ade3-8d24dba36920",
      "metadata": {
        "id": "8ff2dc14-1684-4673-ade3-8d24dba36920"
      },
      "outputs": [],
      "source": [
        "class Temporal_Attention_layer(nn.Module):\n",
        "    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n",
        "        super(Temporal_Attention_layer, self).__init__()\n",
        "        self.U1 = nn.Parameter(torch.FloatTensor(num_of_vertices).to(DEVICE))\n",
        "        self.U2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_vertices).to(DEVICE))\n",
        "        self.U3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n",
        "        self.be = nn.Parameter(torch.FloatTensor(1, num_of_timesteps, num_of_timesteps).to(DEVICE))\n",
        "        self.Ve = nn.Parameter(torch.FloatTensor(num_of_timesteps, num_of_timesteps).to(DEVICE))\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (B, T, T)\n",
        "        '''\n",
        "        _, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n",
        "\n",
        "        lhs = torch.matmul(torch.matmul(x.permute(0, 3, 2, 1), self.U1), self.U2)\n",
        "        # x:(B, N, F_in, T) -> (B, T, F_in, N)\n",
        "        # (B, T, F_in, N)(N) -> (B,T,F_in)\n",
        "        # (B,T,F_in)(F_in,N)->(B,T,N)\n",
        "\n",
        "        rhs = torch.matmul(self.U3, x)  # (F)(B,N,F,T)->(B, N, T)\n",
        "\n",
        "        product = torch.matmul(lhs, rhs)  # (B,T,N)(B,N,T)->(B,T,T)\n",
        "\n",
        "        E = torch.matmul(self.Ve, torch.sigmoid(product + self.be))  # (B, T, T)\n",
        "\n",
        "        E_normalized = F.softmax(E, dim=1)\n",
        "        ### Temporal Attention score measures the importance of each timesteps fore a node in the Graph\n",
        "        return E_normalized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f0c14f-2f44-46b5-bc40-740f056e802a",
      "metadata": {
        "id": "b0f0c14f-2f44-46b5-bc40-740f056e802a"
      },
      "source": [
        "###### Describing a Singular ASTGCN Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd10da9-ceef-48f6-8d72-ce3baaf47884",
      "metadata": {
        "id": "dbd10da9-ceef-48f6-8d72-ce3baaf47884"
      },
      "outputs": [],
      "source": [
        "class ASTGCN_block(nn.Module):\n",
        "\n",
        "    def __init__(self, DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, num_of_timesteps):\n",
        "        super(ASTGCN_block, self).__init__()\n",
        "        self.TAt = Temporal_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n",
        "        self.SAt = Spatial_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n",
        "        self.cheb_conv_SAt = cheb_conv_withSAt(K, cheb_polynomials, in_channels, nb_chev_filter)\n",
        "\n",
        "        ###Applies convolution along temporal dimension\n",
        "        ##nb_chev_filter relates to order of Chebyshev Polynmials, representing number of chebyshev outputs coming\n",
        "        ### nb_time_filter relates to the number of timesteps for each of the chebyshev output\n",
        "        self.time_conv = nn.Conv2d(nb_chev_filter, nb_time_filter, kernel_size=(1, 3), stride=(1, time_strides), padding=(0, 1))\n",
        "\n",
        "        ####(1x1) convolution is applied for residual connections\n",
        "        self.residual_conv = nn.Conv2d(in_channels, nb_time_filter, kernel_size=(1, 1), stride=(1, time_strides))\n",
        "\n",
        "        ####Normalization Layer\n",
        "        self.ln = nn.LayerNorm(nb_time_filter)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (batch_size, N, F_in, T)\n",
        "        :return: (batch_size, N, nb_time_filter, T)\n",
        "        '''\n",
        "        batch_size, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n",
        "\n",
        "        # Step 1: Temporal attention is computed\n",
        "        temporal_At = self.TAt(x)  # (b, T, T)\n",
        "\n",
        "        # Step 2: Temporal attention is applied on the input because input consists of\n",
        "        # graph signal information of different timesteps\n",
        "        # Temporal attention is applied to focus on temporal correlations between neighbouring timestep data\n",
        "        ## of a node\n",
        "        x_TAt = torch.matmul(x.reshape(batch_size, -1, num_of_timesteps), temporal_At).reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n",
        "\n",
        "        # Step 3: Spatial Attention is applied on the temporal attention layer output\n",
        "        spatial_At = self.SAt(x_TAt)\n",
        "\n",
        "        # Step 4: Graph Convolution is applied using the Chebyshev Polynlomials of order K on the graph signal and the\n",
        "        # spatial attention layer output, in order to focus on the sptial correlations of (K-1) neighbouring nodes\n",
        "        ## of a certain node in the Graph\n",
        "        spatial_gcn = self.cheb_conv_SAt(x, spatial_At)  # (b,N,F,T)\n",
        "        # spatial_gcn = self.cheb_conv(x)\n",
        "\n",
        "        # convolution along the time axis\n",
        "        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) (1,3)->(b,F,N,T)\n",
        "\n",
        "        # residual shortcut is applied directly on the input signal with the help of a convolution layer\n",
        "        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) (1,1)->(b,F,N,T)\n",
        "\n",
        "        ### Finally, the residual output is equal to the summation of the residual shortcut output and the final\n",
        "        ### output coming from the time-axis layer\n",
        "        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)\n",
        "        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n",
        "\n",
        "        return x_residual"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d84126-2e27-4a4b-9af2-562dd74f2477",
      "metadata": {
        "id": "a3d84126-2e27-4a4b-9af2-562dd74f2477"
      },
      "source": [
        "###### Describing a series of ASTGCN Blocks inside the submodule Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ccf36b7-148b-4fbf-93e0-62694fe8d607",
      "metadata": {
        "id": "7ccf36b7-148b-4fbf-93e0-62694fe8d607"
      },
      "outputs": [],
      "source": [
        "class ASTGCN_submodule(nn.Module):\n",
        "\n",
        "    def __init__(self, DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices):\n",
        "        '''\n",
        "        :param nb_block:\n",
        "        :param in_channels:\n",
        "        :param K:\n",
        "        :param nb_chev_filter:\n",
        "        :param nb_time_filter:\n",
        "        :param time_strides:\n",
        "        :param cheb_polynomials:\n",
        "        :param nb_predict_step:\n",
        "        '''\n",
        "\n",
        "        super(ASTGCN_submodule, self).__init__()\n",
        "\n",
        "        self.BlockList = nn.ModuleList([ASTGCN_block(DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, len_input)])\n",
        "\n",
        "        self.BlockList.extend([ASTGCN_block(DEVICE, nb_time_filter, K, nb_chev_filter, nb_time_filter, 1, cheb_polynomials, num_of_vertices, len_input//time_strides) for _ in range(nb_block-1)])\n",
        "\n",
        "        ###Adding a Final Convolution Layer after the output from the final ASTGCN Block\n",
        "        self.final_conv = nn.Conv2d(int(len_input/time_strides), num_for_predict, kernel_size=(1, nb_time_filter))\n",
        "\n",
        "        self.DEVICE = DEVICE\n",
        "\n",
        "        self.to(DEVICE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (B, N_nodes, F_in, T_in)\n",
        "        :return: (B, N_nodes, T_out)\n",
        "        '''\n",
        "        for block in self.BlockList:\n",
        "            x = block(x)\n",
        "\n",
        "        output = self.final_conv(x.permute(0, 3, 1, 2))[:, :, :, -1].permute(0, 2, 1)\n",
        "        # (b,N,F,T)->(b,T,N,F)-conv<1,F>->(b,c_out*T,N,1)->(b,c_out*T,N)->(b,N,T)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7def723a-84fd-47a9-ad4b-1ede9c649721",
      "metadata": {
        "id": "7def723a-84fd-47a9-ad4b-1ede9c649721"
      },
      "source": [
        "###### Making Model Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d8d435-80ff-40ea-bf18-52222d9ef715",
      "metadata": {
        "id": "86d8d435-80ff-40ea-bf18-52222d9ef715"
      },
      "outputs": [],
      "source": [
        "def make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter,\n",
        "               time_strides, adj_mx, num_for_predict, len_input, num_of_vertices):\n",
        "    '''\n",
        "\n",
        "    :param DEVICE:\n",
        "    :param nb_block:\n",
        "    :param in_channels:\n",
        "    :param K:\n",
        "    :param nb_chev_filter:\n",
        "    :param nb_time_filter:\n",
        "    :param time_strides:\n",
        "    :param cheb_polynomials:\n",
        "    :param nb_predict_step:\n",
        "    :param len_input\n",
        "    :return:\n",
        "    '''\n",
        "    L_tilde = scaled_Laplacian(adj_mx)\n",
        "    cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n",
        "    model = ASTGCN_submodule(DEVICE, nb_block, in_channels, K,\n",
        "                             nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials,\n",
        "                             num_for_predict, len_input, num_of_vertices)\n",
        "\n",
        "    ###Applying Xavier Initialization to parameters having diemnsion > 1\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "        else:\n",
        "            nn.init.uniform_(p)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bbe8e8c-6b19-4f81-9e72-7f5f9e601e05",
      "metadata": {
        "id": "7bbe8e8c-6b19-4f81-9e72-7f5f9e601e05"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOi3Pjn78cT2",
        "outputId": "4decf3d3-04e4-4fe5-8a84-12d1d304d97e"
      },
      "id": "rOi3Pjn78cT2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRJHh0cx8iJk",
        "outputId": "a68d7b3a-a339-4634-ea2b-fcdd18867c4c"
      },
      "id": "vRJHh0cx8iJk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b59a5bd-bbf7-427a-ba88-0bfafcfdf217",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b59a5bd-bbf7-427a-ba88-0bfafcfdf217",
        "outputId": "6017d0fb-a434-4654-d432-f9b738d15ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: True cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from time import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from scipy.sparse.linalg import eigs\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device('cuda:0')\n",
        "print(\"CUDA:\", USE_CUDA, DEVICE)\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "sw = SummaryWriter(logdir='.', flush_secs=5)\n",
        "\n",
        "import math\n",
        "from typing import Optional, List, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.typing import OptTensor\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.transforms import LaplacianLambdaMax\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, get_laplacian\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "#from torch_scatter import scatter_add"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099556f5-1671-4e73-b86b-f3e9c4806acf",
      "metadata": {
        "id": "099556f5-1671-4e73-b86b-f3e9c4806acf"
      },
      "source": [
        "###### Loading the Dataset and dividing the Dataset into Training, Testing and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea11a6b9-d7a1-40de-957a-155f86ab4c70",
      "metadata": {
        "id": "ea11a6b9-d7a1-40de-957a-155f86ab4c70"
      },
      "outputs": [],
      "source": [
        "def load_graphdata_channel1(batch_size,shuffle=True, DEVICE = torch.device('cuda:0')):\n",
        "    '''\n",
        "    :param DEVICE:\n",
        "    :param batch_size: int\n",
        "    :return:\n",
        "    three DataLoaders, each dataloader contains:\n",
        "    test_x_tensor: (B, N_nodes, in_feature, T_input)\n",
        "    test_decoder_input_tensor: (B, N_nodes, T_output)\n",
        "    test_target_tensor: (B, N_nodes, T_output)\n",
        "    '''\n",
        "\n",
        "    #file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n",
        "    #filename = os.path.join('../input/processing-traffic-data-for-deep-learning-projects/', file + '_r' + str(num_of_hours) + '_d' + str(num_of_days) + '_w' + str(num_of_weeks)) +'_astcgn'\n",
        "    #print('load file:', filename)\n",
        "\n",
        "    file_data = np.load(r\"/content/drive/MyDrive/COMP9491_ASTGCN_Model/Experiment for daily Segment/PEMS07_r0_d2_w0_astcgn.npz\")\n",
        "    train_x = file_data['train_x']  # (10181, 307, 3, 24)\n",
        "    train_x = train_x[:, :, 0:1, :]\n",
        "    train_target = file_data['train_target']  # (10181, 307, 24)\n",
        "\n",
        "    val_x = file_data['val_x']\n",
        "    val_x = val_x[:, :, 0:1, :]\n",
        "    val_target = file_data['val_target']\n",
        "\n",
        "    test_x = file_data['test_x']\n",
        "    test_x = test_x[:, :, 0:1, :]\n",
        "    test_target = file_data['test_target']\n",
        "\n",
        "    mean = file_data['mean'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
        "    std = file_data['std'][:, :, 0:1, :]  # (1, 1, 3, 1)\n",
        "\n",
        "    # ------- train_loader -------\n",
        "    train_x_tensor = torch.from_numpy(train_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "    train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "    train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    # ------- val_loader -------\n",
        "    val_x_tensor = torch.from_numpy(val_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "    val_target_tensor = torch.from_numpy(val_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "    val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # ------- test_loader -------\n",
        "    test_x_tensor = torch.from_numpy(test_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "    test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "    test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # print\n",
        "    print('train:', train_x_tensor.size(), train_target_tensor.size())\n",
        "    print('val:', val_x_tensor.size(), val_target_tensor.size())\n",
        "    print('test:', test_x_tensor.size(), test_target_tensor.size())\n",
        "\n",
        "    return train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c91f6a-b0c4-494c-a9c5-9d79e1333f44",
      "metadata": {
        "id": "18c91f6a-b0c4-494c-a9c5-9d79e1333f44"
      },
      "source": [
        "###### Loading the Data and receiving the dimensions of training, testing and validation tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac7523b-4e22-4431-ad3c-669284d05850",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fac7523b-4e22-4431-ad3c-669284d05850",
        "outputId": "615ec22a-ce22-489e-97df-c472fea05967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: torch.Size([16582, 883, 1, 24]) torch.Size([16582, 883, 12])\n",
            "val: torch.Size([5527, 883, 1, 24]) torch.Size([5527, 883, 12])\n",
            "test: torch.Size([5528, 883, 1, 24]) torch.Size([5528, 883, 12])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, _mean, _std = load_graphdata_channel1(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d96da2fc-35d0-47a0-ade7-f78ea7a8e049",
      "metadata": {
        "id": "d96da2fc-35d0-47a0-ade7-f78ea7a8e049"
      },
      "source": [
        "###### Function To Obtain Adjacenecy Matrix from the Graph Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e76bc1d-540c-48c8-b662-0379ef6ac60b",
      "metadata": {
        "id": "9e76bc1d-540c-48c8-b662-0379ef6ac60b"
      },
      "outputs": [],
      "source": [
        "def get_adjacency_matrix(distance_df_filename, num_of_vertices, id_filename=None):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    distance_df_filename: str, path of the csv file contains edges information\n",
        "    num_of_vertices: int, the number of vertices\n",
        "    Returns\n",
        "    ----------\n",
        "    A: np.ndarray, adjacency matrix\n",
        "    '''\n",
        "    if 'npy' in distance_df_filename:  # false\n",
        "        adj_mx = np.load(distance_df_filename)\n",
        "        return adj_mx, None\n",
        "    else:\n",
        "\n",
        "        #--------------------------------------------- read from here\n",
        "        import csv\n",
        "        A = np.zeros((int(num_of_vertices), int(num_of_vertices)),dtype=np.float32)\n",
        "        distaneA = np.zeros((int(num_of_vertices), int(num_of_vertices)), dtype=np.float32)\n",
        "\n",
        "        #------------ Ignore\n",
        "        if id_filename: # false\n",
        "            with open(id_filename, 'r') as f:\n",
        "                id_dict = {int(i): idx for idx, i in enumerate(f.read().strip().split('\\n'))}  # 把节点id（idx）映射成从0开始的索引\n",
        "\n",
        "            with open(distance_df_filename, 'r') as f:\n",
        "                f.readline()\n",
        "                reader = csv.reader(f)\n",
        "                for row in reader:\n",
        "                    if len(row) != 3:\n",
        "                        continue\n",
        "                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
        "                    A[id_dict[i], id_dict[j]] = 1\n",
        "                    distaneA[id_dict[i], id_dict[j]] = distance\n",
        "            return A, distaneA\n",
        "\n",
        "        else:\n",
        "         #-------------Continue reading\n",
        "            with open(distance_df_filename, 'r') as f:\n",
        "                f.readline()\n",
        "                reader = csv.reader(f)\n",
        "                for row in reader:\n",
        "                    if len(row) != 3:\n",
        "                        continue\n",
        "                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
        "                    A[i, j] = 1\n",
        "                    distaneA[i, j] = distance\n",
        "            return A, distaneA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6b33b8-55ac-4a6c-9443-c21f8c8a98d3",
      "metadata": {
        "id": "0a6b33b8-55ac-4a6c-9443-c21f8c8a98d3"
      },
      "outputs": [],
      "source": [
        "id_filename = None\n",
        "adj_filename = r'/content/drive/MyDrive/COMP9491_ASTGCN_Model/Dataset_PEMS07/PEMS07.csv'\n",
        "num_of_vertices = 883\n",
        "adj_mx, distance_mx = get_adjacency_matrix(adj_filename, num_of_vertices, id_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b47792-b522-463a-a51c-75e67484ee60",
      "metadata": {
        "id": "56b47792-b522-463a-a51c-75e67484ee60"
      },
      "outputs": [],
      "source": [
        "model_daily = make_model(DEVICE, 2, 1, 4,\n",
        "                        64, 64, 2, adj_mx,\n",
        "                        12, 24, 883)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2855386a-e2f4-4c73-8595-6ef4a9e24456",
      "metadata": {
        "id": "2855386a-e2f4-4c73-8595-6ef4a9e24456"
      },
      "source": [
        "###### Printing the Configuration of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377df7cf-a6df-4522-9bd5-4072c24bebe0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "377df7cf-a6df-4522-9bd5-4072c24bebe0",
        "outputId": "d42eb880-83ec-43a4-98ee-e292964b66b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASTGCN_submodule(\n",
            "  (BlockList): ModuleList(\n",
            "    (0): ASTGCN_block(\n",
            "      (TAt): Temporal_Attention_layer()\n",
            "      (SAt): Spatial_Attention_layer()\n",
            "      (cheb_conv_SAt): cheb_conv_withSAt(\n",
            "        (Theta): ParameterList(\n",
            "            (0): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n",
            "            (1): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n",
            "            (2): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n",
            "            (3): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n",
            "        )\n",
            "      )\n",
            "      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
            "      (residual_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 2))\n",
            "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): ASTGCN_block(\n",
            "      (TAt): Temporal_Attention_layer()\n",
            "      (SAt): Spatial_Attention_layer()\n",
            "      (cheb_conv_SAt): cheb_conv_withSAt(\n",
            "        (Theta): ParameterList(\n",
            "            (0): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n",
            "            (1): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n",
            "            (2): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n",
            "            (3): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n",
            "        )\n",
            "      )\n",
            "      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "      (residual_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (final_conv): Conv2d(12, 12, kernel_size=(1, 64), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model_daily)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "387728e5-1c92-4d7e-be7f-e75023315e42",
      "metadata": {
        "id": "387728e5-1c92-4d7e-be7f-e75023315e42"
      },
      "source": [
        "###### Printing the Parameter Size and Configurations of the Model\n",
        "###### Initializing the Learning Rate and Optimizer for the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f335097-ebb8-453f-b2dc-43ec38d7c419",
      "metadata": {
        "id": "4f335097-ebb8-453f-b2dc-43ec38d7c419"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model_daily.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad5c33cf-e03b-47cc-a7a3-6682c0ad4fd0",
      "metadata": {
        "id": "ad5c33cf-e03b-47cc-a7a3-6682c0ad4fd0"
      },
      "source": [
        "###### Displaying the Size of the Parameter tensor and the device in which the tensors are stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84aabfac-8b2f-4a27-9921-7327674484d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84aabfac-8b2f-4a27-9921-7327674484d3",
        "outputId": "df69fd73-91d9-43ac-99c2-975be29b0409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net's state_dict:\n",
            "BlockList.0.TAt.U1 \t torch.Size([883]) \t cuda:0\n",
            "BlockList.0.TAt.U2 \t torch.Size([1, 883]) \t cuda:0\n",
            "BlockList.0.TAt.U3 \t torch.Size([1]) \t cuda:0\n",
            "BlockList.0.TAt.be \t torch.Size([1, 24, 24]) \t cuda:0\n",
            "BlockList.0.TAt.Ve \t torch.Size([24, 24]) \t cuda:0\n",
            "BlockList.0.SAt.W1 \t torch.Size([24]) \t cuda:0\n",
            "BlockList.0.SAt.W2 \t torch.Size([1, 24]) \t cuda:0\n",
            "BlockList.0.SAt.W3 \t torch.Size([1]) \t cuda:0\n",
            "BlockList.0.SAt.bs \t torch.Size([1, 883, 883]) \t cuda:0\n",
            "BlockList.0.SAt.Vs \t torch.Size([883, 883]) \t cuda:0\n",
            "BlockList.0.cheb_conv_SAt.Theta.0 \t torch.Size([1, 64]) \t cuda:0\n",
            "BlockList.0.cheb_conv_SAt.Theta.1 \t torch.Size([1, 64]) \t cuda:0\n",
            "BlockList.0.cheb_conv_SAt.Theta.2 \t torch.Size([1, 64]) \t cuda:0\n",
            "BlockList.0.cheb_conv_SAt.Theta.3 \t torch.Size([1, 64]) \t cuda:0\n",
            "BlockList.0.time_conv.weight \t torch.Size([64, 64, 1, 3]) \t cuda:0\n",
            "BlockList.0.time_conv.bias \t torch.Size([64]) \t cuda:0\n",
            "BlockList.0.residual_conv.weight \t torch.Size([64, 1, 1, 1]) \t cuda:0\n",
            "BlockList.0.residual_conv.bias \t torch.Size([64]) \t cuda:0\n",
            "BlockList.0.ln.weight \t torch.Size([64]) \t cuda:0\n",
            "BlockList.0.ln.bias \t torch.Size([64]) \t cuda:0\n",
            "BlockList.1.TAt.U1 \t torch.Size([883]) \t cuda:0\n",
            "BlockList.1.TAt.U2 \t torch.Size([64, 883]) \t cuda:0\n",
            "BlockList.1.TAt.U3 \t torch.Size([64]) \t cuda:0\n",
            "BlockList.1.TAt.be \t torch.Size([1, 12, 12]) \t cuda:0\n",
            "BlockList.1.TAt.Ve \t torch.Size([12, 12]) \t cuda:0\n",
            "BlockList.1.SAt.W1 \t torch.Size([12]) \t cuda:0\n",
            "BlockList.1.SAt.W2 \t torch.Size([64, 12]) \t cuda:0\n",
            "BlockList.1.SAt.W3 \t torch.Size([64]) \t cuda:0\n",
            "BlockList.1.SAt.bs \t torch.Size([1, 883, 883]) \t cuda:0\n",
            "BlockList.1.SAt.Vs \t torch.Size([883, 883]) \t cuda:0\n",
            "BlockList.1.cheb_conv_SAt.Theta.0 \t torch.Size([64, 64]) \t cuda:0\n",
            "BlockList.1.cheb_conv_SAt.Theta.1 \t torch.Size([64, 64]) \t cuda:0\n",
            "BlockList.1.cheb_conv_SAt.Theta.2 \t torch.Size([64, 64]) \t cuda:0\n",
            "BlockList.1.cheb_conv_SAt.Theta.3 \t torch.Size([64, 64]) \t cuda:0\n",
            "BlockList.1.time_conv.weight \t torch.Size([64, 64, 1, 3]) \t cuda:0\n",
            "BlockList.1.time_conv.bias \t torch.Size([64]) \t cuda:0\n",
            "BlockList.1.residual_conv.weight \t torch.Size([64, 64, 1, 1]) \t cuda:0\n",
            "BlockList.1.residual_conv.bias \t torch.Size([64]) \t cuda:0\n",
            "BlockList.1.ln.weight \t torch.Size([64]) \t cuda:0\n",
            "BlockList.1.ln.bias \t torch.Size([64]) \t cuda:0\n",
            "final_conv.weight \t torch.Size([12, 12, 1, 64]) \t cuda:0\n",
            "final_conv.bias \t torch.Size([12]) \t cuda:0\n",
            "Net's total params: 3235431\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]}]\n"
          ]
        }
      ],
      "source": [
        "print('Net\\'s state_dict:')\n",
        "total_param = 0\n",
        "for param_tensor in model_daily.state_dict():\n",
        "    print(param_tensor, '\\t', model_daily.state_dict()[param_tensor].size(), '\\t', model_daily.state_dict()[param_tensor].device)\n",
        "    total_param += np.prod(model_daily.state_dict()[param_tensor].size())\n",
        "print('Net\\'s total params:', total_param)\n",
        "#--------------------------------------------------\n",
        "print('Optimizer\\'s state_dict:')\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, '\\t', optimizer.state_dict()[var_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8861f5a-b88d-4168-ad70-b8a1f0ba8de1",
      "metadata": {
        "id": "e8861f5a-b88d-4168-ad70-b8a1f0ba8de1"
      },
      "source": [
        "###### Defining the Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f425d21a-6f89-4538-95b4-ad1243e06c4a",
      "metadata": {
        "id": "f425d21a-6f89-4538-95b4-ad1243e06c4a"
      },
      "outputs": [],
      "source": [
        "def masked_mape_np(y_true, y_pred, null_val=np.nan):\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        if np.isnan(null_val):\n",
        "            mask = ~np.isnan(y_true)\n",
        "        else:\n",
        "            mask = np.not_equal(y_true, null_val)\n",
        "        mask = mask.astype('float32')\n",
        "        mask /= np.mean(mask)\n",
        "        mape = np.abs(np.divide(np.subtract(y_pred, y_true).astype('float32'),\n",
        "                      y_true))\n",
        "        mape = np.nan_to_num(mask * mape)\n",
        "        return np.mean(mape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce48348a-b067-42be-b6f2-7f68da895a8a",
      "metadata": {
        "id": "ce48348a-b067-42be-b6f2-7f68da895a8a"
      },
      "outputs": [],
      "source": [
        "def masked_mse(preds, labels, null_val=np.nan):\n",
        "    if np.isnan(null_val):\n",
        "        mask = ~torch.isnan(labels)\n",
        "    else:\n",
        "        mask = (labels != null_val)\n",
        "    mask = mask.float()\n",
        "    # print(mask.sum())\n",
        "    # print(mask.shape[0]*mask.shape[1]*mask.shape[2])\n",
        "    mask /= torch.mean((mask))\n",
        "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
        "    loss = (preds - labels)**2\n",
        "    loss = loss * mask\n",
        "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
        "    return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a20fa73-7cf7-4d94-85ce-95f55787d884",
      "metadata": {
        "id": "1a20fa73-7cf7-4d94-85ce-95f55787d884"
      },
      "outputs": [],
      "source": [
        "def masked_rmse(preds, labels, null_val=np.nan):\n",
        "    return torch.sqrt(masked_mse(preds=preds, labels=labels,\n",
        "                                 null_val=null_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c643032-5938-45ce-85b0-a5e0e232c4a5",
      "metadata": {
        "id": "7c643032-5938-45ce-85b0-a5e0e232c4a5"
      },
      "outputs": [],
      "source": [
        "def masked_mae(preds, labels, null_val=np.nan):\n",
        "    if np.isnan(null_val):\n",
        "        ###creates a mask where values are present are set to True\n",
        "        #### where missing values are present, are set to False\n",
        "        mask = ~torch.isnan(labels)\n",
        "    else:\n",
        "        ### if there is no missing value, create a mask where values are False\n",
        "        mask = (labels != null_val)\n",
        "    mask = mask.float()\n",
        "\n",
        "    ##normalizing the weight of the mask, by dividing with mean of mask values\n",
        "    mask /= torch.mean((mask))\n",
        "\n",
        "    ##Replaces any Missing value in Mask with Zero\n",
        "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
        "    loss = torch.abs(preds - labels)\n",
        "    loss = loss * mask\n",
        "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
        "\n",
        "    ##Computing the meas value of mean absolute error\n",
        "    return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd233516-6b42-4075-bade-5744e5f7809d",
      "metadata": {
        "id": "cd233516-6b42-4075-bade-5744e5f7809d"
      },
      "outputs": [],
      "source": [
        "def masked_mae_test(y_true, y_pred, null_val=np.nan):\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        if np.isnan(null_val):\n",
        "            mask = ~np.isnan(y_true)\n",
        "        else:\n",
        "            mask = np.not_equal(y_true, null_val)\n",
        "        mask = mask.astype('float32')\n",
        "        mask /= np.mean(mask)\n",
        "        mae = np.abs(np.subtract(y_pred, y_true).astype('float32'),\n",
        "                      )\n",
        "        mae = np.nan_to_num(mask * mae)\n",
        "        return np.mean(mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b255a176-fc81-4aa2-b003-1ea84c065c27",
      "metadata": {
        "id": "b255a176-fc81-4aa2-b003-1ea84c065c27"
      },
      "outputs": [],
      "source": [
        "def masked_rmse_test(y_true, y_pred, null_val=np.nan):\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        if np.isnan(null_val):\n",
        "            mask = ~np.isnan(y_true)\n",
        "        else:\n",
        "            # null_val=null_val\n",
        "            mask = np.not_equal(y_true, null_val)\n",
        "        mask = mask.astype('float32')\n",
        "        mask /= np.mean(mask)\n",
        "        mse = ((y_pred- y_true)**2)\n",
        "        mse = np.nan_to_num(mask * mse)\n",
        "        return np.sqrt(np.mean(mse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213d67f5-4a58-43c5-a89e-80c82592851b",
      "metadata": {
        "id": "213d67f5-4a58-43c5-a89e-80c82592851b"
      },
      "source": [
        "###### Setting Up of Variables for Chossing the Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a30e14b-0764-4945-b29b-acd67905836b",
      "metadata": {
        "id": "2a30e14b-0764-4945-b29b-acd67905836b"
      },
      "outputs": [],
      "source": [
        "masked_flag=0\n",
        "criterion = nn.L1Loss().to(DEVICE)\n",
        "criterion_masked = masked_mae\n",
        "loss_function = 'mse'\n",
        "\n",
        "metric_method = 'unmask'\n",
        "missing_value=0.0\n",
        "\n",
        "\n",
        "if loss_function=='masked_mse':\n",
        "    criterion_masked = masked_mse         #nn.MSELoss().to(DEVICE)\n",
        "    masked_flag=1\n",
        "elif loss_function=='masked_mae':\n",
        "    criterion_masked = masked_mae\n",
        "    masked_flag = 1\n",
        "elif loss_function == 'mae':\n",
        "    criterion = nn.L1Loss().to(DEVICE)\n",
        "    ###indicating that standard loss function will be used\n",
        "    masked_flag = 0\n",
        "elif loss_function == 'rmse':\n",
        "    criterion = nn.MSELoss().to(DEVICE)\n",
        "    masked_flag= 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0aea391-53ae-4463-af44-d83b514c6d39",
      "metadata": {
        "id": "a0aea391-53ae-4463-af44-d83b514c6d39"
      },
      "outputs": [],
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "sw = SummaryWriter(logdir='.', flush_secs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "601f1ab6-f5f9-4758-8bf1-f54e709c69de",
      "metadata": {
        "id": "601f1ab6-f5f9-4758-8bf1-f54e709c69de"
      },
      "source": [
        "###### Function for Computing Validation Loss for the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c4bdf0-c8b3-4722-a5a6-cb345ed5592d",
      "metadata": {
        "id": "27c4bdf0-c8b3-4722-a5a6-cb345ed5592d"
      },
      "outputs": [],
      "source": [
        "def compute_val_loss_astgcn(net, val_loader, criterion,  masked_flag,missing_value,sw, epoch, limit=None):\n",
        "    '''\n",
        "    for rnn, compute mean loss on validation set\n",
        "    :param net: model\n",
        "    :param val_loader: torch.utils.data.utils.DataLoader\n",
        "    :param criterion: torch.nn.MSELoss\n",
        "    :param sw: tensorboardX.SummaryWriter\n",
        "    :param global_step: int, current global_step\n",
        "    :param limit: int,\n",
        "    :return: val_loss\n",
        "    '''\n",
        "\n",
        "    net.train(False)  # ensure dropout layers are in evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        val_loader_length = len(val_loader)  # nb of batch\n",
        "\n",
        "        tmp = []  # batch loss\n",
        "\n",
        "        for batch_index, batch_data in enumerate(val_loader):\n",
        "            encoder_inputs, labels = batch_data\n",
        "            outputs = net(encoder_inputs)\n",
        "            if masked_flag:\n",
        "                loss = criterion(outputs, labels, missing_value)\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            tmp.append(loss.item())\n",
        "            if batch_index % 100 == 0:\n",
        "                print('validation batch %s / %s, loss: %.2f' % (batch_index + 1, val_loader_length, loss.item()))\n",
        "            if (limit is not None) and batch_index >= limit:\n",
        "                break\n",
        "\n",
        "        validation_loss = sum(tmp) / len(tmp)\n",
        "        sw.add_scalar('validation_loss', validation_loss, epoch)\n",
        "    return validation_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c707a16-c0af-405a-b20e-c297abea8b9f",
      "metadata": {
        "id": "3c707a16-c0af-405a-b20e-c297abea8b9f"
      },
      "outputs": [],
      "source": [
        "global_step = 0\n",
        "best_epoch = 0\n",
        "best_val_loss = np.inf\n",
        "start_time= time()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1094611f-f408-4339-8ae2-a325d2a2a320",
      "metadata": {
        "id": "1094611f-f408-4339-8ae2-a325d2a2a320"
      },
      "source": [
        "###### Training Loop Starts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8af7519c-3ddb-4354-bdad-57dbc75b71aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8af7519c-3ddb-4354-bdad-57dbc75b71aa",
        "outputId": "89d2b5af-791f-418b-e005-bd0105754fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation batch 1 / 87, loss: 415.76\n",
            "save parameters to file: ./dailyk4_epoch_0.params\n",
            "global step: 200, training loss: 147.81, time: 467.22s\n",
            "validation batch 1 / 87, loss: 142.38\n",
            "save parameters to file: ./dailyk4_epoch_1.params\n",
            "global step: 400, training loss: 62.21, time: 916.81s\n",
            "validation batch 1 / 87, loss: 46.09\n",
            "save parameters to file: ./dailyk4_epoch_2.params\n",
            "global step: 600, training loss: 57.40, time: 1366.86s\n",
            "validation batch 1 / 87, loss: 38.48\n",
            "save parameters to file: ./dailyk4_epoch_3.params\n",
            "global step: 800, training loss: 58.56, time: 1816.94s\n",
            "global step: 1000, training loss: 48.67, time: 2210.53s\n",
            "validation batch 1 / 87, loss: 37.45\n",
            "save parameters to file: ./dailyk4_epoch_4.params\n",
            "global step: 1200, training loss: 63.46, time: 2660.49s\n",
            "validation batch 1 / 87, loss: 36.21\n",
            "save parameters to file: ./dailyk4_epoch_5.params\n",
            "global step: 1400, training loss: 45.10, time: 3110.45s\n",
            "validation batch 1 / 87, loss: 39.57\n",
            "save parameters to file: ./dailyk4_epoch_6.params\n",
            "global step: 1600, training loss: 54.59, time: 3560.90s\n",
            "global step: 1800, training loss: 45.87, time: 3954.89s\n",
            "validation batch 1 / 87, loss: 39.10\n",
            "save parameters to file: ./dailyk4_epoch_7.params\n",
            "global step: 2000, training loss: 38.60, time: 4405.33s\n",
            "validation batch 1 / 87, loss: 38.05\n",
            "save parameters to file: ./dailyk4_epoch_8.params\n",
            "global step: 2200, training loss: 36.56, time: 4855.53s\n",
            "validation batch 1 / 87, loss: 36.96\n",
            "save parameters to file: ./dailyk4_epoch_9.params\n",
            "global step: 2400, training loss: 33.54, time: 5305.46s\n",
            "global step: 2600, training loss: 36.61, time: 5696.74s\n",
            "validation batch 1 / 87, loss: 36.57\n",
            "save parameters to file: ./dailyk4_epoch_10.params\n",
            "global step: 2800, training loss: 32.98, time: 6148.44s\n",
            "validation batch 1 / 87, loss: 37.58\n",
            "global step: 3000, training loss: 31.57, time: 6598.75s\n",
            "validation batch 1 / 87, loss: 35.61\n",
            "save parameters to file: ./dailyk4_epoch_12.params\n",
            "global step: 3200, training loss: 31.22, time: 7048.78s\n",
            "validation batch 1 / 87, loss: 35.78\n",
            "global step: 3400, training loss: 28.91, time: 7498.90s\n",
            "global step: 3600, training loss: 28.14, time: 7892.09s\n",
            "validation batch 1 / 87, loss: 35.20\n",
            "global step: 3800, training loss: 30.50, time: 8342.16s\n",
            "validation batch 1 / 87, loss: 35.11\n",
            "save parameters to file: ./dailyk4_epoch_15.params\n",
            "global step: 4000, training loss: 26.26, time: 8792.18s\n",
            "validation batch 1 / 87, loss: 34.68\n",
            "save parameters to file: ./dailyk4_epoch_16.params\n",
            "global step: 4200, training loss: 31.24, time: 9242.12s\n",
            "global step: 4400, training loss: 28.67, time: 9635.39s\n",
            "validation batch 1 / 87, loss: 35.56\n",
            "global step: 4600, training loss: 28.18, time: 10085.31s\n",
            "validation batch 1 / 87, loss: 34.23\n",
            "save parameters to file: ./dailyk4_epoch_18.params\n",
            "global step: 4800, training loss: 27.79, time: 10535.26s\n",
            "validation batch 1 / 87, loss: 34.15\n",
            "global step: 5000, training loss: 26.81, time: 10985.16s\n",
            "global step: 5200, training loss: 22.97, time: 11376.61s\n",
            "best epoch: 18\n"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "#masked_flag = 0\n",
        "for epoch in range(20):\n",
        "\n",
        "    params_filename = os.path.join('./', 'dailyk4_epoch_%s.params' % epoch)\n",
        "    masked_flag = 1\n",
        "\n",
        "    if masked_flag:\n",
        "        val_loss = compute_val_loss_astgcn(model_daily, val_loader, criterion_masked, masked_flag,missing_value,sw, epoch)\n",
        "    else:\n",
        "        val_loss = compute_val_loss_astgcn(model_daily, val_loader, criterion, masked_flag, missing_value, sw, epoch)\n",
        "\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "        torch.save(model_daily.state_dict(), params_filename)\n",
        "        print('save parameters to file: %s' % params_filename)\n",
        "\n",
        "    model_daily.train()  # ensure dropout layers are in train mode\n",
        "\n",
        "    for batch_index, batch_data in enumerate(train_loader):\n",
        "\n",
        "        encoder_inputs, labels = batch_data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model_daily(encoder_inputs)\n",
        "\n",
        "        if masked_flag:\n",
        "            loss = criterion_masked(outputs, labels,missing_value)\n",
        "        else :\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss = loss.item()\n",
        "\n",
        "        global_step += 1\n",
        "\n",
        "        sw.add_scalar('training_loss', training_loss, global_step)\n",
        "\n",
        "        if global_step % 200 == 0:\n",
        "\n",
        "            print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step, training_loss, time() - start_time))\n",
        "\n",
        "print('best epoch:', best_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150ab6f2-1ef0-48ee-ae73-5f47ad7d0dbe",
      "metadata": {
        "id": "150ab6f2-1ef0-48ee-ae73-5f47ad7d0dbe"
      },
      "outputs": [],
      "source": [
        "def re_normalization(x, mean, std):\n",
        "    x = x * std + mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def max_min_normalization(x, _max, _min):\n",
        "    x = 1. * (x - _min)/(_max - _min)\n",
        "    x = x * 2. - 1.\n",
        "    return x\n",
        "\n",
        "\n",
        "def re_max_min_normalization(x, _max, _min):\n",
        "    x = (x + 1.) / 2.\n",
        "    x = 1. * x * (_max - _min) + _min\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_save_results_astgcn(net, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type):\n",
        "    '''\n",
        "\n",
        "    :param net: nn.Module\n",
        "    :param data_loader: torch.utils.data.utils.DataLoader\n",
        "    :param data_target_tensor: tensor\n",
        "    :param epoch: int\n",
        "    :param _mean: (1, 1, 3, 1)\n",
        "    :param _std: (1, 1, 3, 1)\n",
        "    :param params_path: the path for saving the results\n",
        "    :return:\n",
        "    '''\n",
        "    net.train(False)  # ensure dropout layers are in test mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        data_target_tensor = data_target_tensor.cpu().numpy()\n",
        "\n",
        "        loader_length = len(data_loader)  # nb of batch\n",
        "\n",
        "        prediction = []  #storing the batch output\n",
        "\n",
        "        input = []  #storing the batch input\n",
        "\n",
        "        for batch_index, batch_data in enumerate(data_loader):\n",
        "\n",
        "            encoder_inputs, labels = batch_data\n",
        "\n",
        "            ##Taking only the single input feature\n",
        "            input.append(encoder_inputs[:, :, 0:1].cpu().numpy())  # (batch, T', 1)\n",
        "\n",
        "            outputs = net(encoder_inputs)\n",
        "\n",
        "            prediction.append(outputs.detach().cpu().numpy())\n",
        "\n",
        "            if batch_index % 100 == 0:\n",
        "                print('predicting data set batch %s / %s' % (batch_index + 1, loader_length))\n",
        "\n",
        "        input = np.concatenate(input, 0)\n",
        "\n",
        "        input = re_normalization(input, _mean, _std)\n",
        "\n",
        "        prediction = np.concatenate(prediction, 0)  # (batch, T', 1)\n",
        "\n",
        "        print('input:', input.shape)\n",
        "        print('prediction:', prediction.shape)\n",
        "        print('data_target_tensor:', data_target_tensor.shape)\n",
        "        output_filename = os.path.join(params_path, 'Daily_K4_output_epoch_%s_%s' % (global_step, type))\n",
        "        np.savez(output_filename, input=input, prediction=prediction, data_target_tensor=data_target_tensor)\n",
        "\n",
        "\n",
        "        excel_list = []\n",
        "\n",
        "        ###prediction length has the shape of feature of a certain node\n",
        "        prediction_length = prediction.shape[2]\n",
        "\n",
        "        for i in range(prediction_length):\n",
        "\n",
        "            ### ensuring number of data samples in target sensor is same as that of prediction tensor\n",
        "            assert data_target_tensor.shape[0] == prediction.shape[0]\n",
        "            print('current epoch: %s, predict %s points' % (global_step, i))\n",
        "            if metric_method == 'mask':\n",
        "\n",
        "                ## calculating the value of the feature prediction of each node for T timesteps\n",
        "                mae = masked_mae_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n",
        "                rmse = masked_rmse_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n",
        "                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n",
        "            else :\n",
        "                mae = mean_absolute_error(data_target_tensor[:, :, i], prediction[:, :, i])\n",
        "                rmse = mean_squared_error(data_target_tensor[:, :, i], prediction[:, :, i]) ** 0.5\n",
        "                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n",
        "            print('MAE: %.2f' % (mae))\n",
        "            print('RMSE: %.2f' % (rmse))\n",
        "            print('MAPE: %.2f' % (mape))\n",
        "            excel_list.extend([mae, rmse, mape])\n",
        "\n",
        "        # print overall results\n",
        "        if metric_method == 'mask':\n",
        "            mae = masked_mae_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n",
        "            rmse = masked_rmse_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n",
        "            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n",
        "        else :\n",
        "            mae = mean_absolute_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1))\n",
        "            rmse = mean_squared_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1)) ** 0.5\n",
        "            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n",
        "        print('all MAE: %.2f' % (mae))\n",
        "        print('all RMSE: %.2f' % (rmse))\n",
        "        print('all MAPE: %.2f' % (mape))\n",
        "        excel_list.extend([mae, rmse, mape])\n",
        "        print(excel_list)"
      ],
      "metadata": {
        "id": "gTJq7sqaSmHh"
      },
      "id": "gTJq7sqaSmHh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_main(global_step, data_loader, data_target_tensor,metric_method, _mean, _std, type):\n",
        "    '''\n",
        "\n",
        "    :param global_step: int\n",
        "    :param data_loader: torch.utils.data.utils.DataLoader\n",
        "    :param data_target_tensor: tensor\n",
        "    :param mean: (1, 1, 3, 1)\n",
        "    :param std: (1, 1, 3, 1)\n",
        "    :param type: string\n",
        "    :return:\n",
        "    '''\n",
        "    params_path = '/content/drive/MyDrive/COMP9491_ASTGCN_Model/Dataset_PEMS07/Best_Epoch_Saved_Recent/'\n",
        "    params_filename = os.path.join(params_path, 'dailyk4_epoch_%s.params' % global_step)\n",
        "    print('load weight from:', params_filename)\n",
        "\n",
        "    model_daily.load_state_dict(torch.load(params_filename))\n",
        "\n",
        "    predict_and_save_results_astgcn(model_daily, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type)"
      ],
      "metadata": {
        "id": "TNnLo1lQS4-m"
      },
      "id": "TNnLo1lQS4-m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_main(best_epoch,test_loader, test_target_tensor,'unmask', _mean, _std, 'test' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEUmH_NvUvj4",
        "outputId": "1a2f4b1c-eab6-4d80-bea5-4537306cfd0a"
      },
      "id": "TEUmH_NvUvj4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load weight from: /content/drive/MyDrive/COMP9491_ASTGCN_Model/Dataset_PEMS07/Best_Epoch_Saved_Recent/dailyk4_epoch_18.params\n",
            "predicting data set batch 1 / 87\n",
            "input: (5528, 883, 1, 24)\n",
            "prediction: (5528, 883, 12)\n",
            "data_target_tensor: (5528, 883, 12)\n",
            "current epoch: 18, predict 0 points\n",
            "MAE: 42.23\n",
            "RMSE: 64.29\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 1 points\n",
            "MAE: 41.75\n",
            "RMSE: 63.88\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 2 points\n",
            "MAE: 41.54\n",
            "RMSE: 63.74\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 3 points\n",
            "MAE: 41.38\n",
            "RMSE: 63.59\n",
            "MAPE: 0.18\n",
            "current epoch: 18, predict 4 points\n",
            "MAE: 41.34\n",
            "RMSE: 63.60\n",
            "MAPE: 0.18\n",
            "current epoch: 18, predict 5 points\n",
            "MAE: 41.40\n",
            "RMSE: 63.71\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 6 points\n",
            "MAE: 41.60\n",
            "RMSE: 63.99\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 7 points\n",
            "MAE: 41.93\n",
            "RMSE: 64.43\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 8 points\n",
            "MAE: 42.33\n",
            "RMSE: 64.99\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 9 points\n",
            "MAE: 42.89\n",
            "RMSE: 65.74\n",
            "MAPE: 0.19\n",
            "current epoch: 18, predict 10 points\n",
            "MAE: 43.55\n",
            "RMSE: 66.66\n",
            "MAPE: 0.20\n",
            "current epoch: 18, predict 11 points\n",
            "MAE: 44.60\n",
            "RMSE: 68.08\n",
            "MAPE: 0.21\n",
            "all MAE: 42.21\n",
            "all RMSE: 64.74\n",
            "all MAPE: 0.19\n",
            "[42.228924, 64.28563275044432, 0.19223286, 41.754566, 63.87596317766958, 0.18820536, 41.542526, 63.736056609343, 0.1853457, 41.37887, 63.58860928239232, 0.18446352, 41.338737, 63.59835479335826, 0.18441506, 41.404118, 63.714563910434755, 0.18542548, 41.596264, 63.9874102607302, 0.18708524, 41.927593, 64.43066843636072, 0.18905589, 42.326954, 64.98736731208804, 0.19125853, 42.889484, 65.73565447708914, 0.19485874, 43.55159, 66.664120638232, 0.19972426, 44.604378, 68.08296438216024, 0.20578161, 42.212017, 64.73830658770548, 0.19065382]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}