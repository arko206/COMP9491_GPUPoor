{"cells":[{"cell_type":"code","execution_count":1,"id":"0c1b82d8-020f-41f8-a2b3-0aaece979d63","metadata":{"id":"0c1b82d8-020f-41f8-a2b3-0aaece979d63","executionInfo":{"status":"ok","timestamp":1723010892914,"user_tz":-600,"elapsed":4569,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.utils.data\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from scipy.sparse.linalg import eigs"]},{"cell_type":"markdown","id":"82d8481f-a13a-4dd9-9a5a-06ca71fa246d","metadata":{"id":"82d8481f-a13a-4dd9-9a5a-06ca71fa246d"},"source":["###### Function for Computing Scaled Laplacian"]},{"cell_type":"code","execution_count":2,"id":"0f71d24b-f868-44a1-b402-e36aeb6cbdef","metadata":{"id":"0f71d24b-f868-44a1-b402-e36aeb6cbdef","executionInfo":{"status":"ok","timestamp":1723010910242,"user_tz":-600,"elapsed":913,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def scaled_Laplacian(W):\n","    '''\n","    compute \\tilde{L}\n","\n","    Parameters\n","    ----------\n","    W: np.ndarray, shape is (N, N), N is the num of vertices\n","\n","    Returns\n","    ----------\n","    scaled_Laplacian: np.ndarray, shape (N, N)\n","\n","    '''\n","    ###Checking if the number of rows and columns of an adjacenecy matrix\n","    ####are same or not\n","    assert W.shape[0] == W.shape[1]\n","\n","    ### First sum each row of the adjacency matrix, and we obtain the degress of each vertex in that row\n","    ### Secondly, a diagonal matrix has been created with degree of each vertex in the diagonal\n","    #### Finally, 'D' is the sparse matrix containing only degrees of each vertex\n","    D = np.diag(np.sum(W, axis=1))\n","\n","    #### 'l' is the unormalized Laplacian Matrix obtained by subtraction\n","    ### of Adjacenecy Matrix from the Diagonal Matrix\n","    L = D - W\n","\n","    #### First of all from the Laplacian Matrix, with the help of 'eigs' function largest value for eigen value and eigne vector\n","    ##### has been evaluated\n","    #### Secondly, eigen value has been only kept\n","    #### Thirdly, eigen value beign a complex number, only real part is kept and saved as lamda_max\n","    lambda_max = eigs(L, k=1, which='LR')[0].real\n","\n","    #### Finally Scaled Laplacian Matrix value is Obtained\n","    return (2 * L) / lambda_max - np.identity(W.shape[0])\n"]},{"cell_type":"markdown","id":"264a0b1a-5706-4e3e-8e28-191a795bded2","metadata":{"id":"264a0b1a-5706-4e3e-8e28-191a795bded2"},"source":["##### Function for Computing Chebyshev Polynomials"]},{"cell_type":"code","execution_count":3,"id":"e905db82-5f4e-4983-aaa7-ace27f766491","metadata":{"id":"e905db82-5f4e-4983-aaa7-ace27f766491","executionInfo":{"status":"ok","timestamp":1723010916612,"user_tz":-600,"elapsed":594,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def cheb_polynomial(L_tilde, K):\n","    '''\n","    compute a list of chebyshev polynomials from T_0 to T_{K-1}\n","\n","    Parameters\n","    ----------\n","    L_tilde: scaled Laplacian, np.ndarray, shape (N, N)\n","\n","    K: the maximum order of chebyshev polynomials\n","\n","    Returns\n","    ----------\n","    cheb_polynomials: list(np.ndarray), length: K, from T_0 to T_{K-1}\n","\n","    '''\n","    ### The value of N is set to number of rows of a Laplacian Matric\n","    N = L_tilde.shape[0]\n","\n","    ### cheb_polynimials conatins the zeroth order Chebyshev Polynomial T(0) = np.identity(N)\n","    ### and the first order Chebyshev Polynomial T(1) = L_tilde.copy()\n","    cheb_polynomials = [np.identity(N), L_tilde.copy()]\n","\n","    ### The loop computes the next higher order of Chebyshev Polynomials form order 2 to order k\n","    ### The next order recurrence Chebysehev Polynomial is given by Tk(x) =2xTk-1(x)-Tk-2(x)\n","    ## Since the loop starts from order 2, I am experimenting with values K = 3, 4, 5\n","    for i in range(2, K):\n","        cheb_polynomials.append(2 * L_tilde * cheb_polynomials[i - 1] - cheb_polynomials[i - 2])\n","\n","    return cheb_polynomials"]},{"cell_type":"code","execution_count":4,"id":"5d25aa0e-600f-41cf-b213-459c09cf3cc3","metadata":{"id":"5d25aa0e-600f-41cf-b213-459c09cf3cc3","executionInfo":{"status":"ok","timestamp":1723010918369,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","id":"254eae57-0540-4e5f-af4f-853c85bf5fbd","metadata":{"id":"254eae57-0540-4e5f-af4f-853c85bf5fbd"},"source":["###### Defining the Spatial Attention Layer"]},{"cell_type":"code","execution_count":5,"id":"39adb2d0-7a5d-4a2c-946a-099ed30885ff","metadata":{"id":"39adb2d0-7a5d-4a2c-946a-099ed30885ff","executionInfo":{"status":"ok","timestamp":1723010919119,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class Spatial_Attention_layer(nn.Module):\n","    '''\n","    compute spatial attention scores\n","    : in_channels: number of features of a vertex, here for PEMS07, it's 1\n","    : num_of_timesteps represents number of timesegments in the input data\n","    '''\n","    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n","        super(Spatial_Attention_layer, self).__init__()\n","        self.W1 = nn.Parameter(torch.FloatTensor(num_of_timesteps).to(DEVICE))\n","        self.W2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_timesteps).to(DEVICE))\n","        self.W3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n","        self.bs = nn.Parameter(torch.FloatTensor(1, num_of_vertices, num_of_vertices).to(DEVICE))\n","        self.Vs = nn.Parameter(torch.FloatTensor(num_of_vertices, num_of_vertices).to(DEVICE))\n","\n","\n","    def forward(self, x):\n","        '''\n","        :param x: (batch_size, N, F_in, T)\n","        :return: (B,N,N)\n","        '''\n","\n","        lhs = torch.matmul(torch.matmul(x, self.W1), self.W2)  # (b,N,F,T)(T)->(b,N,F)(F,T)->(b,N,T)\n","\n","        rhs = torch.matmul(self.W3, x).transpose(-1, -2)  # (F)(b,N,F,T)->(b,N,T)->(b,T,N)\n","\n","        product = torch.matmul(lhs, rhs)  # (b,N,T)(b,T,N) -> (B, N, N)\n","\n","        S = torch.matmul(self.Vs, torch.sigmoid(product + self.bs))  # (N,N)(B, N, N)->(B,N,N)\n","\n","        ##Normalized Spatial Attention scores observes the spatial dependency between the vertices\n","        S_normalized = F.softmax(S, dim=1)\n","\n","        return S_normalized"]},{"cell_type":"markdown","id":"73bc235e-3f49-4860-8d06-2c5470462e2a","metadata":{"id":"73bc235e-3f49-4860-8d06-2c5470462e2a"},"source":["###### Chebyshev's Convolution with Spatial Attention\n","###### It is alsp known as Graph Convolution with Spatial Attention"]},{"cell_type":"code","execution_count":6,"id":"5fa77ab7-01eb-40c0-801d-26f42aae9c5a","metadata":{"id":"5fa77ab7-01eb-40c0-801d-26f42aae9c5a","executionInfo":{"status":"ok","timestamp":1723010921792,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class cheb_conv_withSAt(nn.Module):\n","    '''\n","    K-order chebyshev graph convolution\n","    '''\n","\n","    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n","        '''\n","        :param K: int\n","        :param in_channles: int, num of channels in the input sequence\n","        :param out_channels: int, num of channels in the output sequence\n","        '''\n","        super(cheb_conv_withSAt, self).__init__()\n","        self.K = K\n","        self.cheb_polynomials = cheb_polynomials\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.DEVICE = cheb_polynomials[0].device\n","\n","        ### Theta consists of a list of learnable weight matrices of each of shape (in_channels x out_channels) for each of the\n","        #### Chebyshev Polynomial, where number of Chebyshev is represneted by 'K'\n","        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n","\n","    def forward(self, x, spatial_attention):\n","        '''\n","        Chebyshev graph convolution operation\n","        :param x: (batch_size, N, F_in, T)\n","        :return: (batch_size, N, F_out, T)\n","        '''\n","        #### Getting shape of the input Graph signal\n","        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n","\n","        outputs = []\n","\n","        for time_step in range(num_of_timesteps):\n","            ####getting the data for a certain time segment\n","            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n","\n","            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n","            #### Looping Over Chebyshev Polynomial Order\n","            #### In order to Perform Graph Convolution Operation with Spatial Attention\n","            for k in range(self.K):\n","\n","                T_k = self.cheb_polynomials[k]  # (N,N)\n","\n","                ###Hadamarad Product between Chebyshev and Spatial Attention\n","                T_k_with_at = T_k.mul(spatial_attention)   # (N,N)*(N,N) = (N,N)\n","\n","                theta_k = self.Theta[k]  # (in_channel, out_channel)\n","\n","                rhs = T_k_with_at.permute(0, 2, 1).matmul(graph_signal)  # (N, N)(b, N, F_in) = (b, N, F_in)\n","\n","                output = output + rhs.matmul(theta_k)  # (b, N, F_in)(F_in, F_out) = (b, N, F_out)\n","            ### Additional dimension is added in order to understand that Graph Concolution\n","            #### for a particular timestamp/timesegment has been done\n","            outputs.append(output.unsqueeze(-1))  # (b, N, F_out, 1)\n","        ####Concatenating the results accross all timesteps and applying Rely activation function\n","        #### on each one of them\n","        return F.relu(torch.cat(outputs, dim=-1))  # (b, N, F_out, T)\n"]},{"cell_type":"markdown","id":"211845b8-ae39-4310-b03b-a136227f3f15","metadata":{"id":"211845b8-ae39-4310-b03b-a136227f3f15"},"source":["###### Temporal Attention Layer"]},{"cell_type":"code","execution_count":7,"id":"8ff2dc14-1684-4673-ade3-8d24dba36920","metadata":{"id":"8ff2dc14-1684-4673-ade3-8d24dba36920","executionInfo":{"status":"ok","timestamp":1723010929193,"user_tz":-600,"elapsed":916,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class Temporal_Attention_layer(nn.Module):\n","    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n","        super(Temporal_Attention_layer, self).__init__()\n","        self.U1 = nn.Parameter(torch.FloatTensor(num_of_vertices).to(DEVICE))\n","        self.U2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_vertices).to(DEVICE))\n","        self.U3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n","        self.be = nn.Parameter(torch.FloatTensor(1, num_of_timesteps, num_of_timesteps).to(DEVICE))\n","        self.Ve = nn.Parameter(torch.FloatTensor(num_of_timesteps, num_of_timesteps).to(DEVICE))\n","\n","    def forward(self, x):\n","        '''\n","        :param x: (batch_size, N, F_in, T)\n","        :return: (B, T, T)\n","        '''\n","        _, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n","\n","        lhs = torch.matmul(torch.matmul(x.permute(0, 3, 2, 1), self.U1), self.U2)\n","        # x:(B, N, F_in, T) -> (B, T, F_in, N)\n","        # (B, T, F_in, N)(N) -> (B,T,F_in)\n","        # (B,T,F_in)(F_in,N)->(B,T,N)\n","\n","        rhs = torch.matmul(self.U3, x)  # (F)(B,N,F,T)->(B, N, T)\n","\n","        product = torch.matmul(lhs, rhs)  # (B,T,N)(B,N,T)->(B,T,T)\n","\n","        E = torch.matmul(self.Ve, torch.sigmoid(product + self.be))  # (B, T, T)\n","\n","        E_normalized = F.softmax(E, dim=1)\n","        ### Temporal Attention score measures the importance of each timesteps fore a node in the Graph\n","        return E_normalized\n"]},{"cell_type":"markdown","id":"b0f0c14f-2f44-46b5-bc40-740f056e802a","metadata":{"id":"b0f0c14f-2f44-46b5-bc40-740f056e802a"},"source":["###### Describing a Singular ASTGCN Block"]},{"cell_type":"code","execution_count":8,"id":"dbd10da9-ceef-48f6-8d72-ce3baaf47884","metadata":{"id":"dbd10da9-ceef-48f6-8d72-ce3baaf47884","executionInfo":{"status":"ok","timestamp":1723010931095,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class ASTGCN_block(nn.Module):\n","\n","    def __init__(self, DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, num_of_timesteps):\n","        super(ASTGCN_block, self).__init__()\n","        self.TAt = Temporal_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n","        self.SAt = Spatial_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n","        self.cheb_conv_SAt = cheb_conv_withSAt(K, cheb_polynomials, in_channels, nb_chev_filter)\n","\n","        ###Applies convolution along temporal dimension\n","        ##nb_chev_filter relates to order of Chebyshev Polynmials, representing number of chebyshev outputs coming\n","        ### nb_time_filter relates to the number of timesteps for each of the chebyshev output\n","        #kernel size depends on the value of K, as mentioned by author depending on the temporal dimension\n","        ## of neighbouring vertices\n","        self.time_conv = nn.Conv2d(nb_chev_filter, nb_time_filter, kernel_size=(1, 3), stride=(1, time_strides), padding=(0, 1))\n","\n","        ####(1x1) convolution is applied for residual connections\n","        self.residual_conv = nn.Conv2d(in_channels, nb_time_filter, kernel_size=(1, 1), stride=(1, time_strides))\n","\n","        ####Normalization Layer\n","        self.ln = nn.LayerNorm(nb_time_filter)\n","\n","    def forward(self, x):\n","        '''\n","        :param x: (batch_size, N, F_in, T)\n","        :return: (batch_size, N, nb_time_filter, T)\n","        '''\n","        batch_size, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n","\n","        # Step 1: Temporal attention is computed\n","        temporal_At = self.TAt(x)  # (b, T, T)\n","\n","        # Step 2: Temporal attention is applied on the input because input consists of\n","        # graph signal information of different timesteps\n","        # Temporal attention is applied to focus on temporal correlations between neighbouring timestep data\n","        ## of a node\n","        x_TAt = torch.matmul(x.reshape(batch_size, -1, num_of_timesteps), temporal_At).reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n","\n","        # Step 3: Spatial Attention is applied on the temporal attention layer output\n","        spatial_At = self.SAt(x_TAt)\n","\n","        # Step 4: Graph Convolution is applied using the Chebyshev Polynlomials of order K on the graph signal and the\n","        # spatial attention layer output, in order to focus on the sptial correlations of (K-1) neighbouring nodes\n","        ## of a certain node in the Graph\n","        spatial_gcn = self.cheb_conv_SAt(x, spatial_At)  # (b,N,F,T)\n","        # spatial_gcn = self.cheb_conv(x)\n","\n","        # convolution along the time axis\n","        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) (1,3)->(b,F,N,T)\n","\n","        #print(\"Shape of x_residual:\", x_residual.shape)\n","        #print(\"Shape of time_conv_output:\", time_conv_output.shape)\n","\n","        # residual shortcut is applied directly on the input signal with the help of a convolution layer\n","        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) (1,1)->(b,F,N,T)\n","\n","        #print(\"Shape of x_residual:\", x_residual.shape)\n","        #print(\"Shape of time_conv_output:\", time_conv_output.shape)\n","\n","        ### Finally, the residual output is equal to the summation of the residual shortcut output and the final\n","        ### output coming from the time-axis layer\n","        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)\n","        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n","\n","        return x_residual"]},{"cell_type":"markdown","id":"a3d84126-2e27-4a4b-9af2-562dd74f2477","metadata":{"id":"a3d84126-2e27-4a4b-9af2-562dd74f2477"},"source":["###### Describing a series of ASTGCN Blocks inside the submodule Class"]},{"cell_type":"code","execution_count":9,"id":"7ccf36b7-148b-4fbf-93e0-62694fe8d607","metadata":{"id":"7ccf36b7-148b-4fbf-93e0-62694fe8d607","executionInfo":{"status":"ok","timestamp":1723010934798,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class ASTGCN_submodule(nn.Module):\n","\n","    def __init__(self, DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices):\n","        '''\n","        :param nb_block:\n","        :param in_channels:\n","        :param K:\n","        :param nb_chev_filter:\n","        :param nb_time_filter:\n","        :param time_strides:\n","        :param cheb_polynomials:\n","        :param nb_predict_step:\n","        '''\n","\n","        super(ASTGCN_submodule, self).__init__()\n","\n","        self.BlockList = nn.ModuleList([ASTGCN_block(DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, len_input)])\n","\n","        self.BlockList.extend([ASTGCN_block(DEVICE, nb_time_filter, K, nb_chev_filter, nb_time_filter, 1, cheb_polynomials, num_of_vertices, len_input//time_strides) for _ in range(nb_block-1)])\n","\n","        ###Adding a Final Convolution Layer after the output from the final ASTGCN Block\n","        self.final_conv = nn.Conv2d(int(len_input/time_strides), num_for_predict, kernel_size=(1, nb_time_filter))\n","\n","        self.DEVICE = DEVICE\n","\n","        self.to(DEVICE)\n","\n","    def forward(self, x):\n","        '''\n","        :param x: (B, N_nodes, F_in, T_in)\n","        :return: (B, N_nodes, T_out)\n","        '''\n","        for block in self.BlockList:\n","            x = block(x)\n","\n","        output = self.final_conv(x.permute(0, 3, 1, 2))[:, :, :, -1].permute(0, 2, 1)\n","        # (b,N,F,T)->(b,T,N,F)-conv<1,F>->(b,c_out*T,N,1)->(b,c_out*T,N)->(b,N,T)\n","\n","        return output\n"]},{"cell_type":"markdown","id":"7def723a-84fd-47a9-ad4b-1ede9c649721","metadata":{"id":"7def723a-84fd-47a9-ad4b-1ede9c649721"},"source":["###### Making Model Function"]},{"cell_type":"code","execution_count":10,"id":"86d8d435-80ff-40ea-bf18-52222d9ef715","metadata":{"id":"86d8d435-80ff-40ea-bf18-52222d9ef715","executionInfo":{"status":"ok","timestamp":1723010941628,"user_tz":-600,"elapsed":1157,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter,\n","               time_strides, adj_mx, num_for_predict, len_input, num_of_vertices):\n","    '''\n","\n","    :param DEVICE:\n","    :param nb_block:\n","    :param in_channels:\n","    :param K:\n","    :param nb_chev_filter:\n","    :param nb_time_filter:\n","    :param time_strides:\n","    :param cheb_polynomials:\n","    :param nb_predict_step:\n","    :param len_input\n","    :return:\n","    '''\n","    L_tilde = scaled_Laplacian(adj_mx)\n","    cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n","    model = ASTGCN_submodule(DEVICE, nb_block, in_channels, K,\n","                             nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials,\n","                             num_for_predict, len_input, num_of_vertices)\n","\n","    ###Applying Xavier Initialization to parameters having diemnsion > 1\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","        else:\n","            nn.init.uniform_(p)\n","\n","    return model"]},{"cell_type":"code","execution_count":11,"id":"7bbe8e8c-6b19-4f81-9e72-7f5f9e601e05","metadata":{"id":"7bbe8e8c-6b19-4f81-9e72-7f5f9e601e05","executionInfo":{"status":"ok","timestamp":1723010942307,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["import torch\n","\n","if torch.cuda.is_available():\n","    DEVICE = torch.device(\"cuda\")\n","else:\n","    DEVICE = torch.device(\"cpu\")"]},{"cell_type":"code","source":["!pip install torch-geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gf2WSjMlRqSn","executionInfo":{"status":"ok","timestamp":1723010948346,"user_tz":-600,"elapsed":4636,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"339ccb46-e068-4e26-8c07-a65860e7aca7"},"id":"gf2WSjMlRqSn","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.3.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.3.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}]},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0OmEiQWPRxK8","executionInfo":{"status":"ok","timestamp":1723010952442,"user_tz":-600,"elapsed":2874,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"43b4e619-83a7-41c5-9e68-90d6c2b70918"},"id":"0OmEiQWPRxK8","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7sL5xhjTP8k","executionInfo":{"status":"ok","timestamp":1723010978359,"user_tz":-600,"elapsed":25919,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"5c65efd5-2b45-44d1-e27d-1f0db09293c2"},"id":"C7sL5xhjTP8k","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":15,"id":"6b59a5bd-bbf7-427a-ba88-0bfafcfdf217","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6b59a5bd-bbf7-427a-ba88-0bfafcfdf217","executionInfo":{"status":"ok","timestamp":1723010993821,"user_tz":-600,"elapsed":3387,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"4e782954-fc4e-400b-cccb-fe60d5ca64a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA: True cuda:0\n"]}],"source":["import os\n","from time import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from scipy.sparse.linalg import eigs\n","\n","\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device('cuda:0')\n","print(\"CUDA:\", USE_CUDA, DEVICE)\n","\n","from tensorboardX import SummaryWriter\n","sw = SummaryWriter(logdir='.', flush_secs=5)\n","\n","import math\n","from typing import Optional, List, Union\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","\n","from torch_geometric.data import Data\n","from torch_geometric.typing import OptTensor\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.transforms import LaplacianLambdaMax\n","from torch_geometric.utils import remove_self_loops, add_self_loops, get_laplacian\n","from torch_geometric.utils import to_dense_adj\n","#from torch_scatter import scatter_add"]},{"cell_type":"markdown","id":"099556f5-1671-4e73-b86b-f3e9c4806acf","metadata":{"id":"099556f5-1671-4e73-b86b-f3e9c4806acf"},"source":["###### Loading the Dataset and dividing the Dataset into Training, Testing and Validation"]},{"cell_type":"code","execution_count":16,"id":"ea11a6b9-d7a1-40de-957a-155f86ab4c70","metadata":{"id":"ea11a6b9-d7a1-40de-957a-155f86ab4c70","executionInfo":{"status":"ok","timestamp":1723011041792,"user_tz":-600,"elapsed":553,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def load_graphdata_channel1(batch_size,shuffle=True, DEVICE = torch.device('cuda:0')):\n","    '''\n","    :param DEVICE:\n","    :param batch_size: int\n","    :return:\n","    three DataLoaders, each dataloader contains:\n","    test_x_tensor: (B, N_nodes, in_feature, T_input)\n","    test_decoder_input_tensor: (B, N_nodes, T_output)\n","    test_target_tensor: (B, N_nodes, T_output)\n","    '''\n","\n","    #file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n","    #filename = os.path.join('../input/processing-traffic-data-for-deep-learning-projects/', file + '_r' + str(num_of_hours) + '_d' + str(num_of_days) + '_w' + str(num_of_weeks)) +'_astcgn'\n","    #print('load file:', filename)\n","\n","    file_data = np.load(r\"/content/drive/MyDrive/COMP9491_ASTGCN_Model/Dataset_PEMS07/PEMS04_304r4_304d0_304w0_astcgn.npz\")\n","    train_x = file_data['train_x']  # (10181, 307, 1, 12)\n","    train_x = train_x[:, :, 0:1, :]\n","    train_target = file_data['train_target']  # (10181, 307, 12)\n","\n","    val_x = file_data['val_x']\n","    val_x = val_x[:, :, 0:1, :]\n","    val_target = file_data['val_target']\n","\n","    test_x = file_data['test_x']\n","    test_x = test_x[:, :, 0:1, :]\n","    test_target = file_data['test_target']\n","\n","    mean = file_data['mean'][:, :, 0:1, :]  # (1, 1, 3, 1)\n","    std = file_data['std'][:, :, 0:1, :]  # (1, 1, 3, 1)\n","\n","    # ------- train_loader -------\n","    train_x_tensor = torch.from_numpy(train_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n","    train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n","    train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    # ------- val_loader -------\n","    val_x_tensor = torch.from_numpy(val_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n","    val_target_tensor = torch.from_numpy(val_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n","    val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor)\n","    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    # ------- test_loader -------\n","    test_x_tensor = torch.from_numpy(test_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n","    test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n","    test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    # print\n","    print('train:', train_x_tensor.size(), train_target_tensor.size())\n","    print('val:', val_x_tensor.size(), val_target_tensor.size())\n","    print('test:', test_x_tensor.size(), test_target_tensor.size())\n","\n","    return train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std"]},{"cell_type":"markdown","id":"18c91f6a-b0c4-494c-a9c5-9d79e1333f44","metadata":{"id":"18c91f6a-b0c4-494c-a9c5-9d79e1333f44"},"source":["###### Loading the Data and receiving the dimensions of training, testing and validation tensors"]},{"cell_type":"code","execution_count":17,"id":"fac7523b-4e22-4431-ad3c-669284d05850","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fac7523b-4e22-4431-ad3c-669284d05850","executionInfo":{"status":"ok","timestamp":1723011054045,"user_tz":-600,"elapsed":9006,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"4eeece83-4b1e-41fd-e8dc-b7a37a510220"},"outputs":[{"output_type":"stream","name":"stdout","text":["train: torch.Size([10186, 307, 1, 12]) torch.Size([10186, 307, 3])\n","val: torch.Size([3396, 307, 1, 12]) torch.Size([3396, 307, 3])\n","test: torch.Size([3396, 307, 1, 12]) torch.Size([3396, 307, 3])\n"]}],"source":["batch_size = 64\n","\n","train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, _mean, _std = load_graphdata_channel1(batch_size)"]},{"cell_type":"markdown","id":"d96da2fc-35d0-47a0-ade7-f78ea7a8e049","metadata":{"id":"d96da2fc-35d0-47a0-ade7-f78ea7a8e049"},"source":["###### Function To Obtain Adjacenecy Matrix from the Graph Data"]},{"cell_type":"code","execution_count":18,"id":"9e76bc1d-540c-48c8-b662-0379ef6ac60b","metadata":{"id":"9e76bc1d-540c-48c8-b662-0379ef6ac60b","executionInfo":{"status":"ok","timestamp":1723011058617,"user_tz":-600,"elapsed":525,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def get_adjacency_matrix(distance_df_filename, num_of_vertices, id_filename=None):\n","    '''\n","    Parameters\n","    ----------\n","    distance_df_filename: str, path of the csv file contains edges information\n","    num_of_vertices: int, the number of vertices\n","    Returns\n","    ----------\n","    A: np.ndarray, adjacency matrix\n","    '''\n","    if 'npy' in distance_df_filename:  # false\n","        adj_mx = np.load(distance_df_filename)\n","        return adj_mx, None\n","    else:\n","\n","        #--------------------------------------------- read from here\n","        import csv\n","        A = np.zeros((int(num_of_vertices), int(num_of_vertices)),dtype=np.float32)\n","        distaneA = np.zeros((int(num_of_vertices), int(num_of_vertices)), dtype=np.float32)\n","\n","        #------------ Ignore\n","        if id_filename: # false\n","            with open(id_filename, 'r') as f:\n","                id_dict = {int(i): idx for idx, i in enumerate(f.read().strip().split('\\n'))}\n","\n","            with open(distance_df_filename, 'r') as f:\n","                f.readline()\n","                reader = csv.reader(f)\n","                for row in reader:\n","                    if len(row) != 3:\n","                        continue\n","                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n","                    A[id_dict[i], id_dict[j]] = 1\n","                    distaneA[id_dict[i], id_dict[j]] = distance\n","            return A, distaneA\n","\n","        else:\n","         #-------------Continue reading\n","            with open(distance_df_filename, 'r') as f:\n","                f.readline()\n","                reader = csv.reader(f)\n","                for row in reader:\n","                    if len(row) != 3:\n","                        continue\n","                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n","                    A[i, j] = 1\n","                    distaneA[i, j] = distance\n","            return A, distaneA"]},{"cell_type":"code","execution_count":19,"id":"0a6b33b8-55ac-4a6c-9443-c21f8c8a98d3","metadata":{"id":"0a6b33b8-55ac-4a6c-9443-c21f8c8a98d3","executionInfo":{"status":"ok","timestamp":1723011063094,"user_tz":-600,"elapsed":1531,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["id_filename = None\n","adj_filename = r'/content/drive/MyDrive/COMP9491_ASTGCN_Model/PEMS04_Recent_K_3_4_5/PEMS04.csv'\n","num_of_vertices = 307\n","adj_mx, distance_mx = get_adjacency_matrix(adj_filename, num_of_vertices, id_filename)"]},{"cell_type":"code","execution_count":20,"id":"f425d21a-6f89-4538-95b4-ad1243e06c4a","metadata":{"id":"f425d21a-6f89-4538-95b4-ad1243e06c4a","executionInfo":{"status":"ok","timestamp":1723011063094,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mape_np(y_true, y_pred, null_val=np.nan):\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        if np.isnan(null_val):\n","            mask = ~np.isnan(y_true)\n","        else:\n","            mask = np.not_equal(y_true, null_val)\n","        mask = mask.astype('float32')\n","        mask /= np.mean(mask)\n","        mape = np.abs(np.divide(np.subtract(y_pred, y_true).astype('float32'),\n","                      y_true))\n","        mape = np.nan_to_num(mask * mape)\n","        return np.mean(mape)"]},{"cell_type":"code","execution_count":21,"id":"ce48348a-b067-42be-b6f2-7f68da895a8a","metadata":{"id":"ce48348a-b067-42be-b6f2-7f68da895a8a","executionInfo":{"status":"ok","timestamp":1723011065863,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mse(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        mask = ~torch.isnan(labels)\n","    else:\n","        mask = (labels != null_val)\n","    mask = mask.float()\n","    # print(mask.sum())\n","    # print(mask.shape[0]*mask.shape[1]*mask.shape[2])\n","    mask /= torch.mean((mask))\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    loss = (preds - labels)**2\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","    return torch.mean(loss)"]},{"cell_type":"code","execution_count":22,"id":"1a20fa73-7cf7-4d94-85ce-95f55787d884","metadata":{"id":"1a20fa73-7cf7-4d94-85ce-95f55787d884","executionInfo":{"status":"ok","timestamp":1723011067445,"user_tz":-600,"elapsed":887,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_rmse(preds, labels, null_val=np.nan):\n","    return torch.sqrt(masked_mse(preds=preds, labels=labels,\n","                                 null_val=null_val))"]},{"cell_type":"code","execution_count":23,"id":"7c643032-5938-45ce-85b0-a5e0e232c4a5","metadata":{"id":"7c643032-5938-45ce-85b0-a5e0e232c4a5","executionInfo":{"status":"ok","timestamp":1723011068166,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mae(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        ###creates a mask where values are present are set to True\n","        #### where missing values are present, are set to False\n","        mask = ~torch.isnan(labels)\n","    else:\n","        ### if there is no missing value, create a mask where values are False\n","        mask = (labels != null_val)\n","    mask = mask.float()\n","\n","    ##normalizing the weight of the mask, by dividing with mean of mask values\n","    mask /= torch.mean((mask))\n","\n","    ##Replaces any Missing value in Mask with Zero\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    loss = torch.abs(preds - labels)\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","\n","    ##Computing the meas value of mean absolute error\n","    return torch.mean(loss)"]},{"cell_type":"code","execution_count":24,"id":"cd233516-6b42-4075-bade-5744e5f7809d","metadata":{"id":"cd233516-6b42-4075-bade-5744e5f7809d","executionInfo":{"status":"ok","timestamp":1723011072543,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mae_test(y_true, y_pred, null_val=np.nan):\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        if np.isnan(null_val):\n","            mask = ~np.isnan(y_true)\n","        else:\n","            mask = np.not_equal(y_true, null_val)\n","        mask = mask.astype('float32')\n","        mask /= np.mean(mask)\n","        mae = np.abs(np.subtract(y_pred, y_true).astype('float32'),\n","                      )\n","        mae = np.nan_to_num(mask * mae)\n","        return np.mean(mae)"]},{"cell_type":"code","execution_count":25,"id":"b255a176-fc81-4aa2-b003-1ea84c065c27","metadata":{"id":"b255a176-fc81-4aa2-b003-1ea84c065c27","executionInfo":{"status":"ok","timestamp":1723011074208,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_rmse_test(y_true, y_pred, null_val=np.nan):\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        if np.isnan(null_val):\n","            mask = ~np.isnan(y_true)\n","        else:\n","            # null_val=null_val\n","            mask = np.not_equal(y_true, null_val)\n","        mask = mask.astype('float32')\n","        mask /= np.mean(mask)\n","        mse = ((y_pred- y_true)**2)\n","        mse = np.nan_to_num(mask * mse)\n","        return np.sqrt(np.mean(mse))"]},{"cell_type":"code","execution_count":26,"id":"2a30e14b-0764-4945-b29b-acd67905836b","metadata":{"id":"2a30e14b-0764-4945-b29b-acd67905836b","executionInfo":{"status":"ok","timestamp":1723011074724,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["masked_flag=0\n","criterion = nn.L1Loss().to(DEVICE)\n","criterion_masked = masked_mae\n","loss_function = 'mse'\n","\n","metric_method = 'unmask'\n","missing_value=0.0\n","\n","\n","if loss_function=='masked_mse':\n","    criterion_masked = masked_mse         #nn.MSELoss().to(DEVICE)\n","    masked_flag=1\n","elif loss_function=='masked_mae':\n","    criterion_masked = masked_mae\n","    masked_flag = 1\n","elif loss_function == 'mae':\n","    criterion = nn.L1Loss().to(DEVICE)\n","    ###indicating that standard loss function will be used\n","    masked_flag = 0\n","elif loss_function == 'rmse':\n","    criterion = nn.MSELoss().to(DEVICE)\n","    masked_flag= 0"]},{"cell_type":"code","source":["model_hour_k4 = make_model(DEVICE, 2, 1, 4,\n","                        64, 64, 1, adj_mx,\n","                        3, 12, 307)"],"metadata":{"id":"w440F8fHIc20","executionInfo":{"status":"ok","timestamp":1723011084019,"user_tz":-600,"elapsed":657,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"w440F8fHIc20","execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(model_hour_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oLNgAcuIr6u","executionInfo":{"status":"ok","timestamp":1723011084912,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"a9633adf-1008-4e59-ca28-14a230cebeda"},"id":"6oLNgAcuIr6u","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["ASTGCN_submodule(\n","  (BlockList): ModuleList(\n","    (0): ASTGCN_block(\n","      (TAt): Temporal_Attention_layer()\n","      (SAt): Spatial_Attention_layer()\n","      (cheb_conv_SAt): cheb_conv_withSAt(\n","        (Theta): ParameterList(\n","            (0): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","            (1): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","            (2): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","            (3): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","        )\n","      )\n","      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (residual_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n","      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): ASTGCN_block(\n","      (TAt): Temporal_Attention_layer()\n","      (SAt): Spatial_Attention_layer()\n","      (cheb_conv_SAt): cheb_conv_withSAt(\n","        (Theta): ParameterList(\n","            (0): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","            (1): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","            (2): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","            (3): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","        )\n","      )\n","      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (residual_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (final_conv): Conv2d(12, 3, kernel_size=(1, 64), stride=(1, 1))\n",")\n"]}]},{"cell_type":"markdown","source":["###### Defining Optimization and Config for Model, K = 4"],"metadata":{"id":"8_1omO2yJKau"},"id":"8_1omO2yJKau"},{"cell_type":"code","source":["learning_rate = 0.001\n","optimizer = optim.Adam(model_hour_k4.parameters(), lr=learning_rate)"],"metadata":{"id":"ok5kOosGI9Fq","executionInfo":{"status":"ok","timestamp":1723011088308,"user_tz":-600,"elapsed":632,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"ok5kOosGI9Fq","execution_count":29,"outputs":[]},{"cell_type":"code","source":["print('Net\\'s state_dict:')\n","total_param = 0\n","for param_tensor in model_hour_k4.state_dict():\n","    print(param_tensor, '\\t', model_hour_k4.state_dict()[param_tensor].size(), '\\t', model_hour_k4.state_dict()[param_tensor].device)\n","    total_param += np.prod(model_hour_k4.state_dict()[param_tensor].size())\n","print('Net\\'s total params:', total_param)\n","#--------------------------------------------------\n","print('Optimizer\\'s state_dict:')\n","for var_name in optimizer.state_dict():\n","    print(var_name, '\\t', optimizer.state_dict()[var_name])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5o2rr_NJB00","executionInfo":{"status":"ok","timestamp":1723011088309,"user_tz":-600,"elapsed":3,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"52d7ae89-da30-4192-ea4c-2e8ef937a5d0"},"id":"A5o2rr_NJB00","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Net's state_dict:\n","BlockList.0.TAt.U1 \t torch.Size([307]) \t cuda:0\n","BlockList.0.TAt.U2 \t torch.Size([1, 307]) \t cuda:0\n","BlockList.0.TAt.U3 \t torch.Size([1]) \t cuda:0\n","BlockList.0.TAt.be \t torch.Size([1, 12, 12]) \t cuda:0\n","BlockList.0.TAt.Ve \t torch.Size([12, 12]) \t cuda:0\n","BlockList.0.SAt.W1 \t torch.Size([12]) \t cuda:0\n","BlockList.0.SAt.W2 \t torch.Size([1, 12]) \t cuda:0\n","BlockList.0.SAt.W3 \t torch.Size([1]) \t cuda:0\n","BlockList.0.SAt.bs \t torch.Size([1, 307, 307]) \t cuda:0\n","BlockList.0.SAt.Vs \t torch.Size([307, 307]) \t cuda:0\n","BlockList.0.cheb_conv_SAt.Theta.0 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.cheb_conv_SAt.Theta.1 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.cheb_conv_SAt.Theta.2 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.cheb_conv_SAt.Theta.3 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.time_conv.weight \t torch.Size([64, 64, 1, 3]) \t cuda:0\n","BlockList.0.time_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.0.residual_conv.weight \t torch.Size([64, 1, 1, 1]) \t cuda:0\n","BlockList.0.residual_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.0.ln.weight \t torch.Size([64]) \t cuda:0\n","BlockList.0.ln.bias \t torch.Size([64]) \t cuda:0\n","BlockList.1.TAt.U1 \t torch.Size([307]) \t cuda:0\n","BlockList.1.TAt.U2 \t torch.Size([64, 307]) \t cuda:0\n","BlockList.1.TAt.U3 \t torch.Size([64]) \t cuda:0\n","BlockList.1.TAt.be \t torch.Size([1, 12, 12]) \t cuda:0\n","BlockList.1.TAt.Ve \t torch.Size([12, 12]) \t cuda:0\n","BlockList.1.SAt.W1 \t torch.Size([12]) \t cuda:0\n","BlockList.1.SAt.W2 \t torch.Size([64, 12]) \t cuda:0\n","BlockList.1.SAt.W3 \t torch.Size([64]) \t cuda:0\n","BlockList.1.SAt.bs \t torch.Size([1, 307, 307]) \t cuda:0\n","BlockList.1.SAt.Vs \t torch.Size([307, 307]) \t cuda:0\n","BlockList.1.cheb_conv_SAt.Theta.0 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.cheb_conv_SAt.Theta.1 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.cheb_conv_SAt.Theta.2 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.cheb_conv_SAt.Theta.3 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.time_conv.weight \t torch.Size([64, 64, 1, 3]) \t cuda:0\n","BlockList.1.time_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.1.residual_conv.weight \t torch.Size([64, 64, 1, 1]) \t cuda:0\n","BlockList.1.residual_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.1.ln.weight \t torch.Size([64]) \t cuda:0\n","BlockList.1.ln.bias \t torch.Size([64]) \t cuda:0\n","final_conv.weight \t torch.Size([3, 12, 1, 64]) \t cuda:0\n","final_conv.bias \t torch.Size([3]) \t cuda:0\n","Net's total params: 447270\n","Optimizer's state_dict:\n","state \t {}\n","param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]}]\n"]}]},{"cell_type":"code","source":["from tensorboardX import SummaryWriter\n","sw = SummaryWriter(logdir='.', flush_secs=5)"],"metadata":{"id":"hVR2oyOdXb_b","executionInfo":{"status":"ok","timestamp":1723011092159,"user_tz":-600,"elapsed":651,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"hVR2oyOdXb_b","execution_count":31,"outputs":[]},{"cell_type":"code","execution_count":32,"id":"27c4bdf0-c8b3-4722-a5a6-cb345ed5592d","metadata":{"id":"27c4bdf0-c8b3-4722-a5a6-cb345ed5592d","executionInfo":{"status":"ok","timestamp":1723011092159,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def compute_val_loss_astgcn(net, val_loader, criterion,  masked_flag,missing_value,sw, epoch, limit=None):\n","    '''\n","    for rnn, compute mean loss on validation set\n","    :param net: model\n","    :param val_loader: torch.utils.data.utils.DataLoader\n","    :param criterion: torch.nn.MSELoss\n","    :param sw: tensorboardX.SummaryWriter\n","    :param global_step: int, current global_step\n","    :param limit: int,\n","    :return: val_loss\n","    '''\n","\n","    net.train(False)  # ensure dropout layers are in evaluation mode\n","\n","    with torch.no_grad():\n","\n","        val_loader_length = len(val_loader)  # nb of batch\n","\n","        tmp = []  # batch loss\n","\n","        for batch_index, batch_data in enumerate(val_loader):\n","            encoder_inputs, labels = batch_data\n","            outputs = net(encoder_inputs)\n","            if masked_flag:\n","                loss = criterion(outputs, labels, missing_value)\n","            else:\n","                loss = criterion(outputs, labels)\n","\n","            tmp.append(loss.item())\n","            if batch_index % 100 == 0:\n","                print('validation batch %s / %s, loss: %.2f' % (batch_index + 1, val_loader_length, loss.item()))\n","            if (limit is not None) and batch_index >= limit:\n","                break\n","\n","        validation_loss = sum(tmp) / len(tmp)\n","        sw.add_scalar('validation_loss', validation_loss, epoch)\n","    return validation_loss\n"]},{"cell_type":"markdown","source":["##### Training for when K =4"],"metadata":{"id":"jGaKGDO1LLAN"},"id":"jGaKGDO1LLAN"},{"cell_type":"code","source":["global_step_k4 = 0\n","best_epoch_k4 = 0\n","best_val_loss_k4 = np.inf\n","start_time= time()"],"metadata":{"id":"qbZGtodbJe7R","executionInfo":{"status":"ok","timestamp":1723011097092,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"qbZGtodbJe7R","execution_count":33,"outputs":[]},{"cell_type":"code","source":["validation_loss_list_k4 = []\n","training_loss_list_k4 = []\n","final_train_loss_k4 = []\n","\n","# train model\n","#masked_flag = 0\n","for epoch in range(20):\n","\n","    params_filename = os.path.join('./', 'PEMS04_3pts_k4_epoch_%s.params' % epoch)\n","    masked_flag = 1\n","\n","    if masked_flag:\n","        val_loss = compute_val_loss_astgcn(model_hour_k4, val_loader, criterion_masked, masked_flag,missing_value,sw, epoch)\n","    else:\n","        val_loss = compute_val_loss_astgcn(model_hour_k4, val_loader, criterion, masked_flag, missing_value, sw, epoch)\n","\n","    ###appending the validation Loss in the List\n","    validation_loss_list_k4.append(val_loss)\n","    if val_loss < best_val_loss_k4:\n","        best_val_loss_k4 = val_loss\n","        best_epoch_k4 = epoch\n","        torch.save(model_hour_k4.state_dict(), params_filename)\n","        print('save parameters to file: %s' % params_filename)\n","\n","    model_hour_k4.train()  # ensure dropout layers are in train mode\n","\n","    for batch_index, batch_data in enumerate(train_loader):\n","\n","        encoder_inputs, labels = batch_data\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model_hour_k4(encoder_inputs)\n","\n","        if masked_flag:\n","            loss = criterion_masked(outputs, labels,missing_value)\n","        else :\n","            loss = criterion(outputs, labels)\n","\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        training_loss_k4 = loss.item()\n","\n","        global_step_k4 += 1\n","\n","        training_loss_list_k4.append(training_loss_k4)\n","\n","        sw.add_scalar('training_loss', training_loss_k4, global_step_k4)\n","        #globalstep_training_loss_list.append(training_loss)\n","\n","        if global_step_k4 % 200 == 0:\n","\n","            print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step_k4, training_loss_k4, time() - start_time))\n","\n","    ##Estimating the Total Training Batch Loss\n","    train_batch_loss_k4 = sum(training_loss_list_k4)/len(training_loss_list_k4)\n","    final_train_loss_k4.append(train_batch_loss_k4)\n","\n","print('best epoch:', best_epoch_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sy_4IqdXJfxx","executionInfo":{"status":"ok","timestamp":1723012406120,"user_tz":-600,"elapsed":1301575,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"84d30a53-7c7e-47dd-8032-1781b994ee13"},"id":"Sy_4IqdXJfxx","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["validation batch 1 / 54, loss: 290.37\n","save parameters to file: ./PEMS04_3pts_k4_epoch_0.params\n","validation batch 1 / 54, loss: 151.37\n","save parameters to file: ./PEMS04_3pts_k4_epoch_1.params\n","global step: 200, training loss: 80.05, time: 95.42s\n","validation batch 1 / 54, loss: 53.56\n","save parameters to file: ./PEMS04_3pts_k4_epoch_2.params\n","global step: 400, training loss: 29.49, time: 175.32s\n","validation batch 1 / 54, loss: 33.04\n","save parameters to file: ./PEMS04_3pts_k4_epoch_3.params\n","global step: 600, training loss: 21.92, time: 255.15s\n","validation batch 1 / 54, loss: 28.05\n","save parameters to file: ./PEMS04_3pts_k4_epoch_4.params\n","global step: 800, training loss: 22.42, time: 334.58s\n","validation batch 1 / 54, loss: 26.85\n","save parameters to file: ./PEMS04_3pts_k4_epoch_5.params\n","validation batch 1 / 54, loss: 25.91\n","save parameters to file: ./PEMS04_3pts_k4_epoch_6.params\n","global step: 1000, training loss: 19.75, time: 420.77s\n","validation batch 1 / 54, loss: 25.46\n","save parameters to file: ./PEMS04_3pts_k4_epoch_7.params\n","global step: 1200, training loss: 19.34, time: 500.39s\n","validation batch 1 / 54, loss: 25.19\n","save parameters to file: ./PEMS04_3pts_k4_epoch_8.params\n","global step: 1400, training loss: 19.71, time: 580.12s\n","validation batch 1 / 54, loss: 25.03\n","global step: 1600, training loss: 20.37, time: 659.55s\n","validation batch 1 / 54, loss: 25.18\n","validation batch 1 / 54, loss: 24.57\n","save parameters to file: ./PEMS04_3pts_k4_epoch_11.params\n","global step: 1800, training loss: 18.43, time: 745.83s\n","validation batch 1 / 54, loss: 24.54\n","save parameters to file: ./PEMS04_3pts_k4_epoch_12.params\n","global step: 2000, training loss: 19.08, time: 825.42s\n","validation batch 1 / 54, loss: 24.51\n","save parameters to file: ./PEMS04_3pts_k4_epoch_13.params\n","global step: 2200, training loss: 18.34, time: 905.19s\n","validation batch 1 / 54, loss: 24.38\n","save parameters to file: ./PEMS04_3pts_k4_epoch_14.params\n","global step: 2400, training loss: 19.55, time: 984.56s\n","validation batch 1 / 54, loss: 24.20\n","validation batch 1 / 54, loss: 24.20\n","save parameters to file: ./PEMS04_3pts_k4_epoch_16.params\n","global step: 2600, training loss: 16.53, time: 1070.72s\n","validation batch 1 / 54, loss: 23.96\n","save parameters to file: ./PEMS04_3pts_k4_epoch_17.params\n","global step: 2800, training loss: 16.80, time: 1150.39s\n","validation batch 1 / 54, loss: 24.45\n","global step: 3000, training loss: 17.29, time: 1230.02s\n","validation batch 1 / 54, loss: 23.76\n","global step: 3200, training loss: 18.79, time: 1309.38s\n","best epoch: 17\n"]}]},{"cell_type":"code","source":["len(validation_loss_list_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADJw_EFWtPnG","executionInfo":{"status":"ok","timestamp":1723012693448,"user_tz":-600,"elapsed":535,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"d44468e9-6f65-427f-f6e9-17a9d02ad3eb"},"id":"ADJw_EFWtPnG","execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["len(final_train_loss_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afQ8788CtVaY","executionInfo":{"status":"ok","timestamp":1723012695341,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"2f1e6c09-3c62-46fc-d07a-848e12a4fee2"},"id":"afQ8788CtVaY","execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["validation_loss_list_k4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBQE2YV_tf1O","executionInfo":{"status":"ok","timestamp":1723012698058,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"92294aff-7a4a-4a38-8898-44bc8c624c63"},"id":"UBQE2YV_tf1O","execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[219.9742317199707,\n"," 110.4128160123472,\n"," 43.47628722367463,\n"," 26.869111290684454,\n"," 23.037677305716056,\n"," 21.91964221883703,\n"," 21.12869946161906,\n"," 20.701951415450484,\n"," 20.28863181008233,\n"," 20.345009220971,\n"," 20.50826191019129,\n"," 19.883104041770654,\n"," 19.736917054211652,\n"," 19.580256303151447,\n"," 19.52108985406381,\n"," 19.667629347907173,\n"," 19.44608175313031,\n"," 19.236726805015845,\n"," 19.67934027424565,\n"," 19.254288496794523]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["final_train_loss_k4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ozx5BPQNtj0O","executionInfo":{"status":"ok","timestamp":1723012702623,"user_tz":-600,"elapsed":899,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"e320da1f-d9ef-431a-b644-960542bef999"},"id":"Ozx5BPQNtj0O","execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[160.31795144081116,\n"," 113.04050695896149,\n"," 85.61802884737651,\n"," 70.01726318299771,\n"," 60.243804564476015,\n"," 53.58560004432996,\n"," 48.752012491226196,\n"," 45.08027220219374,\n"," 42.19868635204103,\n"," 39.87309016823769,\n"," 37.95896653803912,\n"," 36.34588592549165,\n"," 34.97396648021845,\n"," 33.788192262819834,\n"," 32.75368056456248,\n"," 31.842112563550472,\n"," 31.03094351712395,\n"," 30.30598207844628,\n"," 29.653420431049245,\n"," 29.064938099384307]"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["def re_normalization(x, mean, std):\n","    x = x * std + mean\n","    return x\n","\n","\n","def max_min_normalization(x, _max, _min):\n","    x = 1. * (x - _min)/(_max - _min)\n","    x = x * 2. - 1.\n","    return x\n","\n","\n","def re_max_min_normalization(x, _max, _min):\n","    x = (x + 1.) / 2.\n","    x = 1. * x * (_max - _min) + _min\n","    return x\n"],"metadata":{"id":"G-rUZ5U6mr7J","executionInfo":{"status":"ok","timestamp":1723012706800,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"G-rUZ5U6mr7J","execution_count":39,"outputs":[]},{"cell_type":"code","execution_count":40,"id":"150ab6f2-1ef0-48ee-ae73-5f47ad7d0dbe","metadata":{"id":"150ab6f2-1ef0-48ee-ae73-5f47ad7d0dbe","executionInfo":{"status":"ok","timestamp":1723012721180,"user_tz":-600,"elapsed":637,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def predict_and_save_results_astgcn(net, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type):\n","    '''\n","\n","    :param net: nn.Module\n","    :param data_loader: torch.utils.data.utils.DataLoader\n","    :param data_target_tensor: tensor\n","    :param epoch: int\n","    :param _mean: (1, 1, 3, 1)\n","    :param _std: (1, 1, 3, 1)\n","    :param params_path: the path for saving the results\n","    :return:\n","    '''\n","    net.train(False)  # ensure dropout layers are in test mode\n","\n","    with torch.no_grad():\n","\n","        data_target_tensor = data_target_tensor.cpu().numpy()\n","\n","        loader_length = len(data_loader)  # nb of batch\n","\n","        prediction = []  #storing the batch output\n","\n","        input = []  #storing the batch input\n","\n","        for batch_index, batch_data in enumerate(data_loader):\n","\n","            encoder_inputs, labels = batch_data\n","\n","            ##Taking only the single input feature\n","            input.append(encoder_inputs[:, :, 0:1].cpu().numpy())  # (batch, T', 1)\n","\n","            outputs = net(encoder_inputs)\n","\n","            prediction.append(outputs.detach().cpu().numpy())\n","\n","            if batch_index % 100 == 0:\n","                print('predicting data set batch %s / %s' % (batch_index + 1, loader_length))\n","\n","        input = np.concatenate(input, 0)\n","\n","        input = re_normalization(input, _mean, _std)\n","\n","        prediction = np.concatenate(prediction, 0)  # (batch, T', 1)\n","\n","        print('input:', input.shape)\n","        print('prediction:', prediction.shape)\n","        print('data_target_tensor:', data_target_tensor.shape)\n","        output_filename = os.path.join(params_path, 'recent3pts04k4output_epoch_%s_%s' % (global_step, type))\n","        np.savez(output_filename, input=input, prediction=prediction, data_target_tensor=data_target_tensor)\n","\n","\n","        excel_list = []\n","\n","        ###prediction length has the shape of feature of a certain node\n","        prediction_length = prediction.shape[2]\n","\n","        for i in range(prediction_length):\n","\n","            ### ensuring number of data samples in target sensor is same as that of prediction tensor\n","            assert data_target_tensor.shape[0] == prediction.shape[0]\n","            print('current epoch: %s, predict %s points' % (global_step, i))\n","            if metric_method == 'mask':\n","\n","                ## calculating the value of the feature prediction of each node for T timesteps\n","                mae = masked_mae_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n","                rmse = masked_rmse_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n","                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n","            else :\n","                mae = mean_absolute_error(data_target_tensor[:, :, i], prediction[:, :, i])\n","                rmse = mean_squared_error(data_target_tensor[:, :, i], prediction[:, :, i]) ** 0.5\n","                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n","            print('MAE: %.2f' % (mae))\n","            print('RMSE: %.2f' % (rmse))\n","            print('MAPE: %.2f' % (mape))\n","            excel_list.extend([mae, rmse, mape])\n","\n","        # print overall results\n","        if metric_method == 'mask':\n","            mae = masked_mae_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n","            rmse = masked_rmse_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n","            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n","        else :\n","            mae = mean_absolute_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1))\n","            rmse = mean_squared_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1)) ** 0.5\n","            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n","        print('all MAE: %.2f' % (mae))\n","        print('all RMSE: %.2f' % (rmse))\n","        print('all MAPE: %.2f' % (mape))\n","        excel_list.extend([mae, rmse, mape])\n","        print(excel_list)"]},{"cell_type":"code","source":["def predict_main(global_step, data_loader, data_target_tensor,metric_method, _mean, _std, type):\n","    '''\n","\n","    :param global_step: int\n","    :param data_loader: torch.utils.data.utils.DataLoader\n","    :param data_target_tensor: tensor\n","    :param mean: (1, 1, 3, 1)\n","    :param std: (1, 1, 3, 1)\n","    :param type: string\n","    :return:\n","    '''\n","    params_path = '/content/drive/MyDrive/COMP9491_ASTGCN_Model/Dataset_PEMS07/Best_Epoch_Saved_Recent/'\n","    params_filename = os.path.join(params_path, 'PEMS04_3pts_k4_epoch_%s.params' % global_step)\n","    print('load weight from:', params_filename)\n","\n","    model_hour_k4.load_state_dict(torch.load(params_filename))\n","\n","    predict_and_save_results_astgcn(model_hour_k4, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type)"],"metadata":{"id":"-_oXw5bPpVWC","executionInfo":{"status":"ok","timestamp":1723012937970,"user_tz":-600,"elapsed":774,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"-_oXw5bPpVWC","execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["###### Prediction for the Recent Model, when K = 4"],"metadata":{"id":"jkCBeIKVtzKp"},"id":"jkCBeIKVtzKp"},{"cell_type":"code","source":["predict_main(best_epoch_k4,test_loader, test_target_tensor,'unmask', _mean, _std, 'test' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgqTp3GytyiU","executionInfo":{"status":"ok","timestamp":1723013005740,"user_tz":-600,"elapsed":7827,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"c1ad8ee2-af12-46b2-d75b-22aed02eeb70"},"id":"sgqTp3GytyiU","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["load weight from: /content/drive/MyDrive/COMP9491_ASTGCN_Model/Dataset_PEMS07/Best_Epoch_Saved_Recent/PEMS04_3pts_k4_epoch_17.params\n","predicting data set batch 1 / 54\n","input: (3396, 307, 1, 12)\n","prediction: (3396, 307, 3)\n","data_target_tensor: (3396, 307, 3)\n","current epoch: 17, predict 0 points\n","MAE: 19.18\n","RMSE: 30.66\n","MAPE: 0.13\n","current epoch: 17, predict 1 points\n","MAE: 19.64\n","RMSE: 31.37\n","MAPE: 0.14\n","current epoch: 17, predict 2 points\n","MAE: 20.21\n","RMSE: 32.19\n","MAPE: 0.14\n","all MAE: 19.68\n","all RMSE: 31.41\n","all MAPE: 0.14\n","[19.178371, 30.656719861333013, 0.134039, 19.641085, 31.372217062521557, 0.13765338, 20.207907, 32.190774636216624, 0.14109091, 19.675787, 31.412818032114693, 0.13759445]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}