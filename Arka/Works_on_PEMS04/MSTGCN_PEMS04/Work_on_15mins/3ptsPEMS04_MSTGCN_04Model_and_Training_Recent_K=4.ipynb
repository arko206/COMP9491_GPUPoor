{"cells":[{"cell_type":"code","execution_count":1,"id":"0c1b82d8-020f-41f8-a2b3-0aaece979d63","metadata":{"id":"0c1b82d8-020f-41f8-a2b3-0aaece979d63","executionInfo":{"status":"ok","timestamp":1723015462362,"user_tz":-600,"elapsed":4514,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.utils.data\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from scipy.sparse.linalg import eigs"]},{"cell_type":"markdown","id":"82d8481f-a13a-4dd9-9a5a-06ca71fa246d","metadata":{"id":"82d8481f-a13a-4dd9-9a5a-06ca71fa246d"},"source":["###### Function for Computing Scaled Laplacian"]},{"cell_type":"code","execution_count":2,"id":"0f71d24b-f868-44a1-b402-e36aeb6cbdef","metadata":{"id":"0f71d24b-f868-44a1-b402-e36aeb6cbdef","executionInfo":{"status":"ok","timestamp":1723015462362,"user_tz":-600,"elapsed":10,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def scaled_Laplacian(W):\n","    '''\n","    compute \\tilde{L}\n","\n","    Parameters\n","    ----------\n","    W: np.ndarray, shape is (N, N), N is the num of vertices\n","\n","    Returns\n","    ----------\n","    scaled_Laplacian: np.ndarray, shape (N, N)\n","\n","    '''\n","    ###Checking if the number of rows and columns of an adjacenecy matrix\n","    ####are same or not\n","    assert W.shape[0] == W.shape[1]\n","\n","    ### First sum each row of the adjacency matrix, and we obtain the degress of each vertex in that row\n","    ### Secondly, a diagonal matrix has been created with degree of each vertex in the diagonal\n","    #### Finally, 'D' is the sparse matrix containing only degrees of each vertex\n","    D = np.diag(np.sum(W, axis=1))\n","\n","    #### 'l' is the unormalized Laplacian Matrix obtained by subtraction\n","    ### of Adjacenecy Matrix from the Diagonal Matrix\n","    L = D - W\n","\n","    #### First of all from the Laplacian Matrix, with the help of 'eigs' function largest value for eigen value and eigne vector\n","    ##### has been evaluated\n","    #### Secondly, eigen value has been only kept\n","    #### Thirdly, eigen value beign a complex number, only real part is kept and saved as lamda_max\n","    lambda_max = eigs(L, k=1, which='LR')[0].real\n","\n","    #### Finally Scaled Laplacian Matrix value is Obtained\n","    return (2 * L) / lambda_max - np.identity(W.shape[0])\n"]},{"cell_type":"markdown","id":"264a0b1a-5706-4e3e-8e28-191a795bded2","metadata":{"id":"264a0b1a-5706-4e3e-8e28-191a795bded2"},"source":["##### Function for Computing Chebyshev Polynomials"]},{"cell_type":"code","execution_count":3,"id":"e905db82-5f4e-4983-aaa7-ace27f766491","metadata":{"id":"e905db82-5f4e-4983-aaa7-ace27f766491","executionInfo":{"status":"ok","timestamp":1723015473263,"user_tz":-600,"elapsed":528,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def cheb_polynomial(L_tilde, K):\n","    '''\n","    compute a list of chebyshev polynomials from T_0 to T_{K-1}\n","\n","    Parameters\n","    ----------\n","    L_tilde: scaled Laplacian, np.ndarray, shape (N, N)\n","\n","    K: the maximum order of chebyshev polynomials\n","\n","    Returns\n","    ----------\n","    cheb_polynomials: list(np.ndarray), length: K, from T_0 to T_{K-1}\n","\n","    '''\n","    ### The value of N is set to number of rows of a Laplacian Matric\n","    N = L_tilde.shape[0]\n","\n","    ### cheb_polynimials conatins the zeroth order Chebyshev Polynomial T(0) = np.identity(N)\n","    ### and the first order Chebyshev Polynomial T(1) = L_tilde.copy()\n","    cheb_polynomials = [np.identity(N), L_tilde.copy()]\n","\n","    ### The loop computes the next higher order of Chebyshev Polynomials form order 2 to order k\n","    ### The next order recurrence Chebysehev Polynomial is given by Tk(x) =2xTk-1(x)-Tk-2(x)\n","    ## Since the loop starts from order 2, I am experimenting with values K = 3, 4, 5\n","    for i in range(2, K):\n","        cheb_polynomials.append(2 * L_tilde * cheb_polynomials[i - 1] - cheb_polynomials[i - 2])\n","\n","    return cheb_polynomials"]},{"cell_type":"code","execution_count":4,"id":"5d25aa0e-600f-41cf-b213-459c09cf3cc3","metadata":{"id":"5d25aa0e-600f-41cf-b213-459c09cf3cc3","executionInfo":{"status":"ok","timestamp":1723015475644,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","id":"73bc235e-3f49-4860-8d06-2c5470462e2a","metadata":{"id":"73bc235e-3f49-4860-8d06-2c5470462e2a"},"source":["###### Chebyshev's Convolution Layer"]},{"cell_type":"code","execution_count":5,"id":"5fa77ab7-01eb-40c0-801d-26f42aae9c5a","metadata":{"id":"5fa77ab7-01eb-40c0-801d-26f42aae9c5a","executionInfo":{"status":"ok","timestamp":1723015476692,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class cheb_conv(nn.Module):\n","    '''\n","    K-order chebyshev graph convolution\n","    '''\n","\n","    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n","        '''\n","        :param K: int\n","        :param in_channles: int, num of channels in the input sequence\n","        :param out_channels: int, num of channels in the output sequence\n","        '''\n","        super(cheb_conv, self).__init__()\n","        self.K = K\n","        self.cheb_polynomials = cheb_polynomials\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.DEVICE = cheb_polynomials[0].device\n","        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n","\n","    def forward(self, x):\n","        '''\n","        Chebyshev graph convolution operation\n","        :param x: (batch_size, N, F_in, T)\n","        :return: (batch_size, N, F_out, T)\n","        '''\n","\n","        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n","\n","        outputs = []\n","\n","        for time_step in range(num_of_timesteps):\n","\n","            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n","\n","            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n","\n","            for k in range(self.K):\n","\n","                T_k = self.cheb_polynomials[k]  # (N,N)\n","\n","                theta_k = self.Theta[k]  # (in_channel, out_channel)\n","\n","                rhs = graph_signal.permute(0, 2, 1).matmul(T_k).permute(0, 2, 1)\n","\n","                output = output + rhs.matmul(theta_k)\n","\n","            outputs.append(output.unsqueeze(-1))\n","\n","        return F.relu(torch.cat(outputs, dim=-1))\n"]},{"cell_type":"markdown","id":"b0f0c14f-2f44-46b5-bc40-740f056e802a","metadata":{"id":"b0f0c14f-2f44-46b5-bc40-740f056e802a"},"source":["###### Describing a Singular MSTGCN Block"]},{"cell_type":"code","execution_count":6,"id":"dbd10da9-ceef-48f6-8d72-ce3baaf47884","metadata":{"id":"dbd10da9-ceef-48f6-8d72-ce3baaf47884","executionInfo":{"status":"ok","timestamp":1723015481668,"user_tz":-600,"elapsed":1682,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class MSTGCN_block(nn.Module):\n","\n","    def __init__(self, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials):\n","        super(MSTGCN_block, self).__init__()\n","        self.cheb_conv = cheb_conv(K, cheb_polynomials, in_channels, nb_chev_filter)\n","        self.time_conv = nn.Conv2d(nb_chev_filter, nb_time_filter, kernel_size=(1, 3), stride=(1, time_strides), padding=(0, 1))\n","        self.residual_conv = nn.Conv2d(in_channels, nb_time_filter, kernel_size=(1, 1), stride=(1, time_strides))\n","        self.ln = nn.LayerNorm(nb_time_filter)\n","\n","    def forward(self, x):\n","        '''\n","        :param x: (batch_size, N, F_in, T)\n","        :return: (batch_size, N, nb_time_filter, T)\n","        '''\n","        # cheb gcn\n","        spatial_gcn = self.cheb_conv(x)  # (b,N,F,T)\n","\n","        # convolution along the time axis\n","        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  # (b,F,N,T)\n","\n","        # residual shortcut\n","        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,F,N,T)\n","\n","        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)  # (b,N,F,T)\n","\n","        return x_residual"]},{"cell_type":"markdown","id":"a3d84126-2e27-4a4b-9af2-562dd74f2477","metadata":{"id":"a3d84126-2e27-4a4b-9af2-562dd74f2477"},"source":["###### Describing a series of MSTGCN Blocks inside the submodule Class"]},{"cell_type":"code","execution_count":7,"id":"7ccf36b7-148b-4fbf-93e0-62694fe8d607","metadata":{"id":"7ccf36b7-148b-4fbf-93e0-62694fe8d607","executionInfo":{"status":"ok","timestamp":1723015482196,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["class MSTGCN_submodule(nn.Module):\n","\n","    def __init__(self, DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input):\n","        '''\n","        :param nb_block:\n","        :param in_channels:\n","        :param K:\n","        :param nb_chev_filter:\n","        :param nb_time_filter:\n","        :param time_strides:\n","        :param cheb_polynomials:\n","        :param nb_predict_step:\n","        '''\n","\n","        super(MSTGCN_submodule, self).__init__()\n","\n","        self.BlockList = nn.ModuleList([MSTGCN_block(in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials)])\n","\n","        self.BlockList.extend([MSTGCN_block(nb_time_filter, K, nb_chev_filter, nb_time_filter, 1, cheb_polynomials) for _ in range(nb_block-1)])\n","\n","        self.final_conv = nn.Conv2d(int(len_input/time_strides), num_for_predict, kernel_size=(1, nb_time_filter))\n","\n","        self.DEVICE = DEVICE\n","\n","        self.to(DEVICE)\n","\n","    def forward(self, x):\n","        '''\n","        :param x: (B, N_nodes, F_in, T_in)\n","        :return: (B, N_nodes, T_out)\n","        '''\n","        for block in self.BlockList:\n","            x = block(x)\n","\n","        output = self.final_conv(x.permute(0, 3, 1, 2))[:, :, :, -1].permute(0, 2, 1)\n","\n","        return output\n"]},{"cell_type":"markdown","id":"7def723a-84fd-47a9-ad4b-1ede9c649721","metadata":{"id":"7def723a-84fd-47a9-ad4b-1ede9c649721"},"source":["###### Making Model Function"]},{"cell_type":"code","execution_count":8,"id":"86d8d435-80ff-40ea-bf18-52222d9ef715","metadata":{"id":"86d8d435-80ff-40ea-bf18-52222d9ef715","executionInfo":{"status":"ok","timestamp":1723015484506,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, adj_mx, num_for_predict, len_input):\n","    '''\n","\n","    :param DEVICE:\n","    :param nb_block:\n","    :param in_channels:\n","    :param K:\n","    :param nb_chev_filter:\n","    :param nb_time_filter:\n","    :param time_strides:\n","    :param cheb_polynomials:\n","    :param nb_predict_step:\n","    :param len_input\n","    :return:\n","    '''\n","    L_tilde = scaled_Laplacian(adj_mx)\n","    cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n","    model = MSTGCN_submodule(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input)\n","\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","    return model"]},{"cell_type":"code","execution_count":9,"id":"7bbe8e8c-6b19-4f81-9e72-7f5f9e601e05","metadata":{"id":"7bbe8e8c-6b19-4f81-9e72-7f5f9e601e05","executionInfo":{"status":"ok","timestamp":1723015485613,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["import torch\n","\n","if torch.cuda.is_available():\n","    DEVICE = torch.device(\"cuda\")\n","else:\n","    DEVICE = torch.device(\"cpu\")"]},{"cell_type":"code","source":["!pip install torch-geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gf2WSjMlRqSn","executionInfo":{"status":"ok","timestamp":1723015490488,"user_tz":-600,"elapsed":3974,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"b0ed3a9b-92a9-45fb-b650-31feedc5af94"},"id":"gf2WSjMlRqSn","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.3.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.3.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}]},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0OmEiQWPRxK8","executionInfo":{"status":"ok","timestamp":1723015491755,"user_tz":-600,"elapsed":1269,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"c29039b2-070a-45ae-9f92-8d776b0c99ac"},"id":"0OmEiQWPRxK8","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7sL5xhjTP8k","executionInfo":{"status":"ok","timestamp":1723015523765,"user_tz":-600,"elapsed":32012,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"df0868e9-3502-458d-89ce-9ff1a980321b"},"id":"C7sL5xhjTP8k","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":13,"id":"6b59a5bd-bbf7-427a-ba88-0bfafcfdf217","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6b59a5bd-bbf7-427a-ba88-0bfafcfdf217","executionInfo":{"status":"ok","timestamp":1723015571779,"user_tz":-600,"elapsed":3170,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"d1ab05ec-69e3-49e4-ed21-ff2983ddda27"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA: True cuda:0\n"]}],"source":["import os\n","from time import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from scipy.sparse.linalg import eigs\n","\n","\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device('cuda:0')\n","print(\"CUDA:\", USE_CUDA, DEVICE)\n","\n","from tensorboardX import SummaryWriter\n","sw = SummaryWriter(logdir='.', flush_secs=5)\n","\n","import math\n","from typing import Optional, List, Union\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","\n","from torch_geometric.data import Data\n","from torch_geometric.typing import OptTensor\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.transforms import LaplacianLambdaMax\n","from torch_geometric.utils import remove_self_loops, add_self_loops, get_laplacian\n","from torch_geometric.utils import to_dense_adj\n","#from torch_scatter import scatter_add"]},{"cell_type":"markdown","id":"099556f5-1671-4e73-b86b-f3e9c4806acf","metadata":{"id":"099556f5-1671-4e73-b86b-f3e9c4806acf"},"source":["###### Loading the Dataset and dividing the Dataset into Training, Testing and Validation"]},{"cell_type":"code","execution_count":34,"id":"ea11a6b9-d7a1-40de-957a-155f86ab4c70","metadata":{"id":"ea11a6b9-d7a1-40de-957a-155f86ab4c70","executionInfo":{"status":"ok","timestamp":1723015827614,"user_tz":-600,"elapsed":546,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def load_graphdata_channel1(batch_size,shuffle=True, DEVICE = torch.device('cuda:0')):\n","    '''\n","    :param DEVICE:\n","    :param batch_size: int\n","    :return:\n","    three DataLoaders, each dataloader contains:\n","    test_x_tensor: (B, N_nodes, in_feature, T_input)\n","    test_decoder_input_tensor: (B, N_nodes, T_output)\n","    test_target_tensor: (B, N_nodes, T_output)\n","    '''\n","\n","    #file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n","    #filename = os.path.join('../input/processing-traffic-data-for-deep-learning-projects/', file + '_r' + str(num_of_hours) + '_d' + str(num_of_days) + '_w' + str(num_of_weeks)) +'_astcgn'\n","    #print('load file:', filename)\n","\n","    file_data = np.load(\"/content/drive/MyDrive/COMP9491_ASTGCN_Model/Dataset_PEMS07/PEMS04_304r4_304d0_304w0_astcgn.npz\")\n","    train_x = file_data['train_x']  # (10181, 307, 3, 12)\n","    train_x = train_x[:, :, 0:1, :]\n","    train_target = file_data['train_target']  # (10181, 307, 12)\n","\n","    val_x = file_data['val_x']\n","    val_x = val_x[:, :, 0:1, :]\n","    val_target = file_data['val_target']\n","\n","    test_x = file_data['test_x']\n","    test_x = test_x[:, :, 0:1, :]\n","    test_target = file_data['test_target']\n","\n","    mean = file_data['mean'][:, :, 0:1, :]  # (1, 1, 3, 1)\n","    std = file_data['std'][:, :, 0:1, :]  # (1, 1, 3, 1)\n","\n","    # ------- train_loader -------\n","    train_x_tensor = torch.from_numpy(train_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n","    train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n","    train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n","\n","    # ------- val_loader -------\n","    val_x_tensor = torch.from_numpy(val_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n","    val_target_tensor = torch.from_numpy(val_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n","    val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor)\n","    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    # ------- test_loader -------\n","    test_x_tensor = torch.from_numpy(test_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n","    test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n","    test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    # print\n","    print('train:', train_x_tensor.size(), train_target_tensor.size())\n","    print('val:', val_x_tensor.size(), val_target_tensor.size())\n","    print('test:', test_x_tensor.size(), test_target_tensor.size())\n","\n","    return train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std"]},{"cell_type":"markdown","id":"18c91f6a-b0c4-494c-a9c5-9d79e1333f44","metadata":{"id":"18c91f6a-b0c4-494c-a9c5-9d79e1333f44"},"source":["###### Loading the Data and receiving the dimensions of training, testing and validation tensors"]},{"cell_type":"code","execution_count":35,"id":"fac7523b-4e22-4431-ad3c-669284d05850","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fac7523b-4e22-4431-ad3c-669284d05850","executionInfo":{"status":"ok","timestamp":1723015840820,"user_tz":-600,"elapsed":9355,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"4be8670b-d492-4fc3-88b9-31b6364da1e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["train: torch.Size([10186, 307, 1, 12]) torch.Size([10186, 307, 3])\n","val: torch.Size([3396, 307, 1, 12]) torch.Size([3396, 307, 3])\n","test: torch.Size([3396, 307, 1, 12]) torch.Size([3396, 307, 3])\n"]}],"source":["batch_size = 64\n","\n","train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, _mean, _std = load_graphdata_channel1(batch_size)"]},{"cell_type":"markdown","id":"d96da2fc-35d0-47a0-ade7-f78ea7a8e049","metadata":{"id":"d96da2fc-35d0-47a0-ade7-f78ea7a8e049"},"source":["###### Function To Obtain Adjacenecy Matrix from the Graph Data"]},{"cell_type":"code","execution_count":36,"id":"9e76bc1d-540c-48c8-b662-0379ef6ac60b","metadata":{"id":"9e76bc1d-540c-48c8-b662-0379ef6ac60b","executionInfo":{"status":"ok","timestamp":1723015846618,"user_tz":-600,"elapsed":522,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def get_adjacency_matrix(distance_df_filename, num_of_vertices, id_filename=None):\n","    '''\n","    Parameters\n","    ----------\n","    distance_df_filename: str, path of the csv file contains edges information\n","    num_of_vertices: int, the number of vertices\n","    Returns\n","    ----------\n","    A: np.ndarray, adjacency matrix\n","    '''\n","    if 'npy' in distance_df_filename:  # false\n","        adj_mx = np.load(distance_df_filename)\n","        return adj_mx, None\n","    else:\n","\n","        #--------------------------------------------- read from here\n","        import csv\n","        A = np.zeros((int(num_of_vertices), int(num_of_vertices)),dtype=np.float32)\n","        distaneA = np.zeros((int(num_of_vertices), int(num_of_vertices)), dtype=np.float32)\n","\n","        #------------ Ignore\n","        if id_filename: # false\n","            with open(id_filename, 'r') as f:\n","                id_dict = {int(i): idx for idx, i in enumerate(f.read().strip().split('\\n'))}\n","\n","            with open(distance_df_filename, 'r') as f:\n","                f.readline()\n","                reader = csv.reader(f)\n","                for row in reader:\n","                    if len(row) != 3:\n","                        continue\n","                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n","                    A[id_dict[i], id_dict[j]] = 1\n","                    distaneA[id_dict[i], id_dict[j]] = distance\n","            return A, distaneA\n","\n","        else:\n","         #-------------Continue reading\n","            with open(distance_df_filename, 'r') as f:\n","                f.readline()\n","                reader = csv.reader(f)\n","                for row in reader:\n","                    if len(row) != 3:\n","                        continue\n","                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n","                    A[i, j] = 1\n","                    distaneA[i, j] = distance\n","            return A, distaneA"]},{"cell_type":"code","execution_count":37,"id":"0a6b33b8-55ac-4a6c-9443-c21f8c8a98d3","metadata":{"id":"0a6b33b8-55ac-4a6c-9443-c21f8c8a98d3","executionInfo":{"status":"ok","timestamp":1723015853390,"user_tz":-600,"elapsed":549,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["id_filename = None\n","adj_filename = r'/content/drive/MyDrive/COMP9491_ASTGCN_Model/PEMS04_Recent_K_3_4_5/PEMS04.csv'\n","num_of_vertices = 307\n","adj_mx, distance_mx = get_adjacency_matrix(adj_filename, num_of_vertices, id_filename)"]},{"cell_type":"code","execution_count":38,"id":"f425d21a-6f89-4538-95b4-ad1243e06c4a","metadata":{"id":"f425d21a-6f89-4538-95b4-ad1243e06c4a","executionInfo":{"status":"ok","timestamp":1723015855462,"user_tz":-600,"elapsed":1068,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mape_np(y_true, y_pred, null_val=np.nan):\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        if np.isnan(null_val):\n","            mask = ~np.isnan(y_true)\n","        else:\n","            mask = np.not_equal(y_true, null_val)\n","        mask = mask.astype('float32')\n","        mask /= np.mean(mask)\n","        mape = np.abs(np.divide(np.subtract(y_pred, y_true).astype('float32'),\n","                      y_true))\n","        mape = np.nan_to_num(mask * mape)\n","        return np.mean(mape)"]},{"cell_type":"code","execution_count":39,"id":"ce48348a-b067-42be-b6f2-7f68da895a8a","metadata":{"id":"ce48348a-b067-42be-b6f2-7f68da895a8a","executionInfo":{"status":"ok","timestamp":1723015856163,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mse(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        mask = ~torch.isnan(labels)\n","    else:\n","        mask = (labels != null_val)\n","    mask = mask.float()\n","    # print(mask.sum())\n","    # print(mask.shape[0]*mask.shape[1]*mask.shape[2])\n","    mask /= torch.mean((mask))\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    loss = (preds - labels)**2\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","    return torch.mean(loss)"]},{"cell_type":"code","execution_count":40,"id":"1a20fa73-7cf7-4d94-85ce-95f55787d884","metadata":{"id":"1a20fa73-7cf7-4d94-85ce-95f55787d884","executionInfo":{"status":"ok","timestamp":1723015857740,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_rmse(preds, labels, null_val=np.nan):\n","    return torch.sqrt(masked_mse(preds=preds, labels=labels,\n","                                 null_val=null_val))"]},{"cell_type":"code","execution_count":41,"id":"7c643032-5938-45ce-85b0-a5e0e232c4a5","metadata":{"id":"7c643032-5938-45ce-85b0-a5e0e232c4a5","executionInfo":{"status":"ok","timestamp":1723015857740,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mae(preds, labels, null_val=np.nan):\n","    if np.isnan(null_val):\n","        ###creates a mask where values are present are set to True\n","        #### where missing values are present, are set to False\n","        mask = ~torch.isnan(labels)\n","    else:\n","        ### if there is no missing value, create a mask where values are False\n","        mask = (labels != null_val)\n","    mask = mask.float()\n","\n","    ##normalizing the weight of the mask, by dividing with mean of mask values\n","    mask /= torch.mean((mask))\n","\n","    ##Replaces any Missing value in Mask with Zero\n","    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n","    loss = torch.abs(preds - labels)\n","    loss = loss * mask\n","    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n","\n","    ##Computing the meas value of mean absolute error\n","    return torch.mean(loss)"]},{"cell_type":"code","execution_count":42,"id":"cd233516-6b42-4075-bade-5744e5f7809d","metadata":{"id":"cd233516-6b42-4075-bade-5744e5f7809d","executionInfo":{"status":"ok","timestamp":1723015859302,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_mae_test(y_true, y_pred, null_val=np.nan):\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        if np.isnan(null_val):\n","            mask = ~np.isnan(y_true)\n","        else:\n","            mask = np.not_equal(y_true, null_val)\n","        mask = mask.astype('float32')\n","        mask /= np.mean(mask)\n","        mae = np.abs(np.subtract(y_pred, y_true).astype('float32'),\n","                      )\n","        mae = np.nan_to_num(mask * mae)\n","        return np.mean(mae)"]},{"cell_type":"code","execution_count":43,"id":"b255a176-fc81-4aa2-b003-1ea84c065c27","metadata":{"id":"b255a176-fc81-4aa2-b003-1ea84c065c27","executionInfo":{"status":"ok","timestamp":1723015859302,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def masked_rmse_test(y_true, y_pred, null_val=np.nan):\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        if np.isnan(null_val):\n","            mask = ~np.isnan(y_true)\n","        else:\n","            # null_val=null_val\n","            mask = np.not_equal(y_true, null_val)\n","        mask = mask.astype('float32')\n","        mask /= np.mean(mask)\n","        mse = ((y_pred- y_true)**2)\n","        mse = np.nan_to_num(mask * mse)\n","        return np.sqrt(np.mean(mse))"]},{"cell_type":"code","execution_count":44,"id":"2a30e14b-0764-4945-b29b-acd67905836b","metadata":{"id":"2a30e14b-0764-4945-b29b-acd67905836b","executionInfo":{"status":"ok","timestamp":1723015860872,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["masked_flag=0\n","criterion = nn.L1Loss().to(DEVICE)\n","criterion_masked = masked_mae\n","loss_function = 'mse'\n","\n","metric_method = 'unmask'\n","missing_value=0.0\n","\n","\n","if loss_function=='masked_mse':\n","    criterion_masked = masked_mse         #nn.MSELoss().to(DEVICE)\n","    masked_flag=1\n","elif loss_function=='masked_mae':\n","    criterion_masked = masked_mae\n","    masked_flag = 1\n","elif loss_function == 'mae':\n","    criterion = nn.L1Loss().to(DEVICE)\n","    ###indicating that standard loss function will be used\n","    masked_flag = 0\n","elif loss_function == 'rmse':\n","    criterion = nn.MSELoss().to(DEVICE)\n","    masked_flag= 0"]},{"cell_type":"code","source":["model_hour_k4 = make_model(DEVICE, 2, 1, 4,\n","                        64, 64, 1, adj_mx,\n","                        3, 12)"],"metadata":{"id":"w440F8fHIc20","executionInfo":{"status":"ok","timestamp":1723015864042,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"w440F8fHIc20","execution_count":45,"outputs":[]},{"cell_type":"code","source":["print(model_hour_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oLNgAcuIr6u","executionInfo":{"status":"ok","timestamp":1723015865805,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"9988923e-454f-40da-f444-e424f2e6c95a"},"id":"6oLNgAcuIr6u","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["MSTGCN_submodule(\n","  (BlockList): ModuleList(\n","    (0): MSTGCN_block(\n","      (cheb_conv): cheb_conv(\n","        (Theta): ParameterList(\n","            (0): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","            (1): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","            (2): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","            (3): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n","        )\n","      )\n","      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (residual_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n","      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): MSTGCN_block(\n","      (cheb_conv): cheb_conv(\n","        (Theta): ParameterList(\n","            (0): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","            (1): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","            (2): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","            (3): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n","        )\n","      )\n","      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","      (residual_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (final_conv): Conv2d(12, 3, kernel_size=(1, 64), stride=(1, 1))\n",")\n"]}]},{"cell_type":"markdown","source":["###### Defining Optimization and Config for Model, K = 4"],"metadata":{"id":"8_1omO2yJKau"},"id":"8_1omO2yJKau"},{"cell_type":"code","source":["learning_rate = 0.001\n","optimizer = optim.Adam(model_hour_k4.parameters(), lr=learning_rate)"],"metadata":{"id":"ok5kOosGI9Fq","executionInfo":{"status":"ok","timestamp":1723015869258,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"ok5kOosGI9Fq","execution_count":47,"outputs":[]},{"cell_type":"code","source":["print('Net\\'s state_dict:')\n","total_param = 0\n","for param_tensor in model_hour_k4.state_dict():\n","    print(param_tensor, '\\t', model_hour_k4.state_dict()[param_tensor].size(), '\\t', model_hour_k4.state_dict()[param_tensor].device)\n","    total_param += np.prod(model_hour_k4.state_dict()[param_tensor].size())\n","print('Net\\'s total params:', total_param)\n","#--------------------------------------------------\n","print('Optimizer\\'s state_dict:')\n","for var_name in optimizer.state_dict():\n","    print(var_name, '\\t', optimizer.state_dict()[var_name])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5o2rr_NJB00","executionInfo":{"status":"ok","timestamp":1723015869958,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"e831766d-c362-4174-ce18-34844261ce11"},"id":"A5o2rr_NJB00","execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Net's state_dict:\n","BlockList.0.cheb_conv.Theta.0 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.cheb_conv.Theta.1 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.cheb_conv.Theta.2 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.cheb_conv.Theta.3 \t torch.Size([1, 64]) \t cuda:0\n","BlockList.0.time_conv.weight \t torch.Size([64, 64, 1, 3]) \t cuda:0\n","BlockList.0.time_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.0.residual_conv.weight \t torch.Size([64, 1, 1, 1]) \t cuda:0\n","BlockList.0.residual_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.0.ln.weight \t torch.Size([64]) \t cuda:0\n","BlockList.0.ln.bias \t torch.Size([64]) \t cuda:0\n","BlockList.1.cheb_conv.Theta.0 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.cheb_conv.Theta.1 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.cheb_conv.Theta.2 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.cheb_conv.Theta.3 \t torch.Size([64, 64]) \t cuda:0\n","BlockList.1.time_conv.weight \t torch.Size([64, 64, 1, 3]) \t cuda:0\n","BlockList.1.time_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.1.residual_conv.weight \t torch.Size([64, 64, 1, 1]) \t cuda:0\n","BlockList.1.residual_conv.bias \t torch.Size([64]) \t cuda:0\n","BlockList.1.ln.weight \t torch.Size([64]) \t cuda:0\n","BlockList.1.ln.bias \t torch.Size([64]) \t cuda:0\n","final_conv.weight \t torch.Size([3, 12, 1, 64]) \t cuda:0\n","final_conv.bias \t torch.Size([3]) \t cuda:0\n","Net's total params: 48195\n","Optimizer's state_dict:\n","state \t {}\n","param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]}]\n"]}]},{"cell_type":"code","source":["from tensorboardX import SummaryWriter\n","sw = SummaryWriter(logdir='.', flush_secs=5)"],"metadata":{"id":"hVR2oyOdXb_b","executionInfo":{"status":"ok","timestamp":1723015875444,"user_tz":-600,"elapsed":527,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"hVR2oyOdXb_b","execution_count":49,"outputs":[]},{"cell_type":"code","execution_count":50,"id":"27c4bdf0-c8b3-4722-a5a6-cb345ed5592d","metadata":{"id":"27c4bdf0-c8b3-4722-a5a6-cb345ed5592d","executionInfo":{"status":"ok","timestamp":1723015875444,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def compute_val_loss_mstgcn(net, val_loader, criterion,  masked_flag,missing_value,sw, epoch, limit=None):\n","    '''\n","    for rnn, compute mean loss on validation set\n","    :param net: model\n","    :param val_loader: torch.utils.data.utils.DataLoader\n","    :param criterion: torch.nn.MSELoss\n","    :param sw: tensorboardX.SummaryWriter\n","    :param global_step: int, current global_step\n","    :param limit: int,\n","    :return: val_loss\n","    '''\n","\n","    net.train(False)  # ensure dropout layers are in evaluation mode\n","\n","    with torch.no_grad():\n","\n","        val_loader_length = len(val_loader)  # nb of batch\n","\n","        tmp = []  # batch loss\n","\n","        for batch_index, batch_data in enumerate(val_loader):\n","            encoder_inputs, labels = batch_data\n","            outputs = net(encoder_inputs)\n","            if masked_flag:\n","                loss = criterion(outputs, labels, missing_value)\n","            else:\n","                loss = criterion(outputs, labels)\n","\n","            tmp.append(loss.item())\n","            if batch_index % 100 == 0:\n","                print('validation batch %s / %s, loss: %.2f' % (batch_index + 1, val_loader_length, loss.item()))\n","            if (limit is not None) and batch_index >= limit:\n","                break\n","\n","        validation_loss = sum(tmp) / len(tmp)\n","        sw.add_scalar('validation_loss', validation_loss, epoch)\n","    return validation_loss\n"]},{"cell_type":"markdown","source":["##### Training for when K =4"],"metadata":{"id":"jGaKGDO1LLAN"},"id":"jGaKGDO1LLAN"},{"cell_type":"code","source":["global_step_k4 = 0\n","best_epoch_k4 = 0\n","best_val_loss_k4 = np.inf\n","start_time= time()"],"metadata":{"id":"qbZGtodbJe7R","executionInfo":{"status":"ok","timestamp":1723015881175,"user_tz":-600,"elapsed":1,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"qbZGtodbJe7R","execution_count":51,"outputs":[]},{"cell_type":"code","source":["validation_loss_list_k4 = []\n","training_loss_list_k4 = []\n","final_train_loss_k4 = []\n","\n","# train model\n","#masked_flag = 0\n","for epoch in range(20):\n","\n","    params_filename = os.path.join('./', '3ptsk4_04_MSTGCNepoch_%s.params' % epoch)\n","    masked_flag = 1\n","\n","    if masked_flag:\n","        val_loss = compute_val_loss_mstgcn(model_hour_k4, val_loader, criterion_masked, masked_flag,missing_value,sw, epoch)\n","    else:\n","        val_loss = compute_val_loss_mstgcn(model_hour_k4, val_loader, criterion, masked_flag, missing_value, sw, epoch)\n","\n","    ###appending the validation Loss in the List\n","    validation_loss_list_k4.append(val_loss)\n","    if val_loss < best_val_loss_k4:\n","        best_val_loss_k4 = val_loss\n","        best_epoch_k4 = epoch\n","        torch.save(model_hour_k4.state_dict(), params_filename)\n","        print('save parameters to file: %s' % params_filename)\n","\n","    model_hour_k4.train()  # ensure dropout layers are in train mode\n","\n","    for batch_index, batch_data in enumerate(train_loader):\n","\n","        encoder_inputs, labels = batch_data\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model_hour_k4(encoder_inputs)\n","\n","        if masked_flag:\n","            loss = criterion_masked(outputs, labels,missing_value)\n","        else :\n","            loss = criterion(outputs, labels)\n","\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        training_loss_k4 = loss.item()\n","\n","        global_step_k4 += 1\n","\n","        training_loss_list_k4.append(training_loss_k4)\n","\n","        sw.add_scalar('training_loss', training_loss_k4, global_step_k4)\n","        #globalstep_training_loss_list.append(training_loss)\n","\n","        if global_step_k4 % 200 == 0:\n","\n","            print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step_k4, training_loss_k4, time() - start_time))\n","\n","    ##Estimating the Total Training Batch Loss\n","    train_batch_loss_k4 = sum(training_loss_list_k4)/len(training_loss_list_k4)\n","    final_train_loss_k4.append(train_batch_loss_k4)\n","\n","print('best epoch:', best_epoch_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sy_4IqdXJfxx","executionInfo":{"status":"ok","timestamp":1723016531344,"user_tz":-600,"elapsed":645400,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"45f2a2b5-3401-4c83-90f9-09ff5440aea0"},"id":"Sy_4IqdXJfxx","execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["validation batch 1 / 54, loss: 289.49\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_0.params\n","validation batch 1 / 54, loss: 136.29\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_1.params\n","global step: 200, training loss: 71.57, time: 50.47s\n","validation batch 1 / 54, loss: 62.67\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_2.params\n","global step: 400, training loss: 29.79, time: 89.85s\n","validation batch 1 / 54, loss: 33.05\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_3.params\n","global step: 600, training loss: 23.54, time: 129.29s\n","validation batch 1 / 54, loss: 28.89\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_4.params\n","global step: 800, training loss: 13.01, time: 168.51s\n","validation batch 1 / 54, loss: 28.64\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_5.params\n","validation batch 1 / 54, loss: 28.12\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_6.params\n","global step: 1000, training loss: 21.85, time: 211.42s\n","validation batch 1 / 54, loss: 26.01\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_7.params\n","global step: 1200, training loss: 21.02, time: 250.77s\n","validation batch 1 / 54, loss: 25.85\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_8.params\n","global step: 1400, training loss: 19.70, time: 290.02s\n","validation batch 1 / 54, loss: 26.77\n","global step: 1600, training loss: 21.35, time: 329.36s\n","validation batch 1 / 54, loss: 25.70\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_10.params\n","validation batch 1 / 54, loss: 25.51\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_11.params\n","global step: 1800, training loss: 20.81, time: 372.21s\n","validation batch 1 / 54, loss: 26.43\n","global step: 2000, training loss: 19.34, time: 411.57s\n","validation batch 1 / 54, loss: 25.36\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_13.params\n","global step: 2200, training loss: 21.58, time: 450.92s\n","validation batch 1 / 54, loss: 25.71\n","global step: 2400, training loss: 17.72, time: 490.29s\n","validation batch 1 / 54, loss: 25.05\n","validation batch 1 / 54, loss: 25.31\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_16.params\n","global step: 2600, training loss: 18.97, time: 533.26s\n","validation batch 1 / 54, loss: 25.19\n","global step: 2800, training loss: 19.35, time: 572.69s\n","validation batch 1 / 54, loss: 24.90\n","save parameters to file: ./3ptsk4_04_MSTGCNepoch_18.params\n","global step: 3000, training loss: 19.39, time: 612.05s\n","validation batch 1 / 54, loss: 25.89\n","global step: 3200, training loss: 18.98, time: 651.32s\n","best epoch: 18\n"]}]},{"cell_type":"code","source":["len(validation_loss_list_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADJw_EFWtPnG","executionInfo":{"status":"ok","timestamp":1723016769720,"user_tz":-600,"elapsed":708,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"78303988-663a-4940-e9d7-b2cd631a0684"},"id":"ADJw_EFWtPnG","execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["len(final_train_loss_k4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afQ8788CtVaY","executionInfo":{"status":"ok","timestamp":1723016770435,"user_tz":-600,"elapsed":2,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"3cb66fd2-4be4-4a3d-ad47-0d073506bf44"},"id":"afQ8788CtVaY","execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["validation_loss_list_k4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBQE2YV_tf1O","executionInfo":{"status":"ok","timestamp":1723016771978,"user_tz":-600,"elapsed":3,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"c2e3946d-e7d2-4385-f7ce-e1e42a9d593f"},"id":"UBQE2YV_tf1O","execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[219.00568072001138,\n"," 102.004431159408,\n"," 50.493027457484494,\n"," 28.963898340861004,\n"," 24.38037074053729,\n"," 23.966492776517516,\n"," 22.313100073072647,\n"," 21.316636156152796,\n"," 21.081693649291992,\n"," 21.166286521487766,\n"," 20.85486525076407,\n"," 20.768409923270898,\n"," 21.09506423385055,\n"," 20.421952865741872,\n"," 21.119120562518084,\n"," 20.42894600055836,\n"," 20.284611331091988,\n"," 20.286488903893364,\n"," 20.218266204551416,\n"," 20.673595781679506]"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["final_train_loss_k4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ozx5BPQNtj0O","executionInfo":{"status":"ok","timestamp":1723016791582,"user_tz":-600,"elapsed":549,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"86bff0d8-f9fc-4fd9-e84b-a56b2952cd16"},"id":"Ozx5BPQNtj0O","execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[151.376309299469,\n"," 106.79676636457444,\n"," 81.84096157153448,\n"," 67.46072686612607,\n"," 58.40914694905281,\n"," 52.2335536390543,\n"," 47.75826510105814,\n"," 44.36707843914628,\n"," 41.707964926958084,\n"," 39.57351470887661,\n"," 37.81120682575486,\n"," 36.33569546093543,\n"," 35.081915702728125,\n"," 34.000387117266655,\n"," 33.069047855933505,\n"," 32.24879502095282,\n"," 31.523286502150928,\n"," 30.873512607481743,\n"," 30.293754205264545,\n"," 29.7702817222476]"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["def re_normalization(x, mean, std):\n","    x = x * std + mean\n","    return x\n","\n","\n","def max_min_normalization(x, _max, _min):\n","    x = 1. * (x - _min)/(_max - _min)\n","    x = x * 2. - 1.\n","    return x\n","\n","\n","def re_max_min_normalization(x, _max, _min):\n","    x = (x + 1.) / 2.\n","    x = 1. * x * (_max - _min) + _min\n","    return x\n"],"metadata":{"id":"G-rUZ5U6mr7J","executionInfo":{"status":"ok","timestamp":1723016857118,"user_tz":-600,"elapsed":542,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"G-rUZ5U6mr7J","execution_count":57,"outputs":[]},{"cell_type":"code","execution_count":58,"id":"150ab6f2-1ef0-48ee-ae73-5f47ad7d0dbe","metadata":{"id":"150ab6f2-1ef0-48ee-ae73-5f47ad7d0dbe","executionInfo":{"status":"ok","timestamp":1723016874151,"user_tz":-600,"elapsed":1059,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"outputs":[],"source":["def predict_and_save_results_astgcn(net, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type):\n","    '''\n","\n","    :param net: nn.Module\n","    :param data_loader: torch.utils.data.utils.DataLoader\n","    :param data_target_tensor: tensor\n","    :param epoch: int\n","    :param _mean: (1, 1, 3, 1)\n","    :param _std: (1, 1, 3, 1)\n","    :param params_path: the path for saving the results\n","    :return:\n","    '''\n","    net.train(False)  # ensure dropout layers are in test mode\n","\n","    with torch.no_grad():\n","\n","        data_target_tensor = data_target_tensor.cpu().numpy()\n","\n","        loader_length = len(data_loader)  # nb of batch\n","\n","        prediction = []  #storing the batch output\n","\n","        input = []  #storing the batch input\n","\n","        for batch_index, batch_data in enumerate(data_loader):\n","\n","            encoder_inputs, labels = batch_data\n","\n","            ##Taking only the single input feature\n","            input.append(encoder_inputs[:, :, 0:1].cpu().numpy())  # (batch, T', 1)\n","\n","            outputs = net(encoder_inputs)\n","\n","            prediction.append(outputs.detach().cpu().numpy())\n","\n","            if batch_index % 100 == 0:\n","                print('predicting data set batch %s / %s' % (batch_index + 1, loader_length))\n","\n","        input = np.concatenate(input, 0)\n","\n","        input = re_normalization(input, _mean, _std)\n","\n","        prediction = np.concatenate(prediction, 0)  # (batch, T', 1)\n","\n","        print('input:', input.shape)\n","        print('prediction:', prediction.shape)\n","        print('data_target_tensor:', data_target_tensor.shape)\n","        output_filename = os.path.join(params_path, '3pts04recent_MST_k4output_epoch_%s_%s' % (global_step, type))\n","        np.savez(output_filename, input=input, prediction=prediction, data_target_tensor=data_target_tensor)\n","\n","\n","        excel_list = []\n","\n","        ###prediction length has the shape of feature of a certain node\n","        prediction_length = prediction.shape[2]\n","\n","        for i in range(prediction_length):\n","\n","            ### ensuring number of data samples in target sensor is same as that of prediction tensor\n","            assert data_target_tensor.shape[0] == prediction.shape[0]\n","            print('current epoch: %s, predict %s points' % (global_step, i))\n","            if metric_method == 'mask':\n","\n","                ## calculating the value of the feature prediction of each node for T timesteps\n","                mae = masked_mae_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n","                rmse = masked_rmse_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n","                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n","            else :\n","                mae = mean_absolute_error(data_target_tensor[:, :, i], prediction[:, :, i])\n","                rmse = mean_squared_error(data_target_tensor[:, :, i], prediction[:, :, i]) ** 0.5\n","                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n","            print('MAE: %.2f' % (mae))\n","            print('RMSE: %.2f' % (rmse))\n","            print('MAPE: %.2f' % (mape))\n","            excel_list.extend([mae, rmse, mape])\n","\n","        # print overall results\n","        if metric_method == 'mask':\n","            mae = masked_mae_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n","            rmse = masked_rmse_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n","            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n","        else :\n","            mae = mean_absolute_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1))\n","            rmse = mean_squared_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1)) ** 0.5\n","            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n","        print('all MAE: %.2f' % (mae))\n","        print('all RMSE: %.2f' % (rmse))\n","        print('all MAPE: %.2f' % (mape))\n","        excel_list.extend([mae, rmse, mape])\n","        print(excel_list)"]},{"cell_type":"code","source":["def predict_main(global_step, data_loader, data_target_tensor,metric_method, _mean, _std, type):\n","    '''\n","\n","    :param global_step: int\n","    :param data_loader: torch.utils.data.utils.DataLoader\n","    :param data_target_tensor: tensor\n","    :param mean: (1, 1, 3, 1)\n","    :param std: (1, 1, 3, 1)\n","    :param type: string\n","    :return:\n","    '''\n","    params_path = '/content/drive/MyDrive/COMP9491_ASTGCN_Model/MSTGCN_Model_Hourly_07/For_PEMS04/'\n","    params_filename = os.path.join(params_path, '3ptsk4_04_MSTGCNepoch_%s.params' % global_step)\n","    print('load weight from:', params_filename)\n","\n","    model_hour_k4.load_state_dict(torch.load(params_filename))\n","\n","    predict_and_save_results_astgcn(model_hour_k4, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type)"],"metadata":{"id":"-_oXw5bPpVWC","executionInfo":{"status":"ok","timestamp":1723016906057,"user_tz":-600,"elapsed":531,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}}},"id":"-_oXw5bPpVWC","execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["###### Prediction for the Recent Model, when K = 4"],"metadata":{"id":"jkCBeIKVtzKp"},"id":"jkCBeIKVtzKp"},{"cell_type":"code","source":["predict_main(best_epoch_k4,test_loader, test_target_tensor,'unmask', _mean, _std, 'test' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IrNDakX7lnzd","executionInfo":{"status":"ok","timestamp":1723016915113,"user_tz":-600,"elapsed":5795,"user":{"displayName":"Arka Indiana","userId":"05221468928770579974"}},"outputId":"c8b43101-ecca-414b-d7d8-1831878b489d"},"id":"IrNDakX7lnzd","execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["load weight from: /content/drive/MyDrive/COMP9491_ASTGCN_Model/MSTGCN_Model_Hourly_07/For_PEMS04/3ptsk4_04_MSTGCNepoch_18.params\n","predicting data set batch 1 / 54\n","input: (3396, 307, 1, 12)\n","prediction: (3396, 307, 3)\n","data_target_tensor: (3396, 307, 3)\n","current epoch: 18, predict 0 points\n","MAE: 18.10\n","RMSE: 28.91\n","MAPE: 0.13\n","current epoch: 18, predict 1 points\n","MAE: 19.81\n","RMSE: 31.27\n","MAPE: 0.14\n","current epoch: 18, predict 2 points\n","MAE: 21.26\n","RMSE: 33.27\n","MAPE: 0.15\n","all MAE: 19.72\n","all RMSE: 31.20\n","all MAPE: 0.14\n","[18.097017, 28.905737959991935, 0.12601194, 19.805262, 31.268818552543284, 0.13754585, 21.25624, 33.27334303080038, 0.14808065, 19.719513, 31.200407915627682, 0.13721284]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}